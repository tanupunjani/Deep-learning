{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R7USwDrt8wsR",
        "dUAFg7Nsh6Fs",
        "_dUGUcpwjwt6",
        "T-cQ8URcj454",
        "t256mvhMcjmq",
        "S_sytl25vD9b",
        "CVEnd-TD5WXm",
        "uD3QtvS_NHJs",
        "7XwJbbWnOrUK",
        "5PDWBf5efOy_",
        "AYoSulaffiHp",
        "y-Pv7T8vfz0Z",
        "uC6S0gzPgjLk",
        "o9e0DvP6nPr7",
        "9-zzbTpmnbdW",
        "5SWhJJpRn3H0",
        "KRKrQ5YQn_7S",
        "wvs8bBUk3WzI"
      ],
      "authorship_tag": "ABX9TyN+FuJvLcrP0jRhSADIbjFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanupunjani/Mastering-tensorflow/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MaXgDwMfQZS"
      },
      "source": [
        "# Intro to NN with tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YbWdsoJhKln"
      },
      "source": [
        "There are many defitions for a regression problem but in our case we are predicting a numerical variable based on some other combination of variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJGJkXRQij1-"
      },
      "source": [
        "#Import tensorflow\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVjZb9JGjRSm"
      },
      "source": [
        "# Create data and use it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "CYBaEJ6ijWPj",
        "outputId": "fc1df6e4-46d3-4b3d-f975-a203786c37f3"
      },
      "source": [
        "#Create features \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = np.array([-7.0, -4.0 ,-1.0 ,2.0 ,5.0 ,8.0 ,11.0, 14.0])\n",
        "\n",
        "#Create labels\n",
        "y = np.array([3.0 ,6.0 ,9.0 ,12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "#Visualize it \n",
        "plt.scatter(X, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCAzcDXaj7-x",
        "outputId": "140e0b75-3e08-4937-ad5b-cefee63fc569"
      },
      "source": [
        "y == X +10 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIUyyJTqlOJD"
      },
      "source": [
        "# Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1YIxN9DlSFe",
        "outputId": "dc46b62d-548a-4354-c9d3-c2d8e88d6e9c"
      },
      "source": [
        "# Create a demo tensor for our house prediction problem \n",
        "house_info = tf.constant([\"bedroom\",\"garage\", \"kitchen\"])\n",
        "house_price = tf.constant([939000])\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'garage', b'kitchen'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939000], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-utIkoJoloxw"
      },
      "source": [
        "# we want to use X to predict y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btJ0fYAClv2h"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAYbBFqVl045",
        "outputId": "b0c9be69-aa44-4d4a-d1dc-8c0d4bdd626f"
      },
      "source": [
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGsocYaHl28v"
      },
      "source": [
        "## They are scalars and have no dimensions :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJCeyrQKnozl",
        "outputId": "d4b2197a-09f5-407c-fe4a-e4550260dc50"
      },
      "source": [
        "# Turn numpy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYpJFhf6onwq"
      },
      "source": [
        "## Steps in modelling with tensorfow\n",
        "1. **Create a model** - define the input and output layers as well as the hidden layers of the deep learning model.\n",
        "3. **Compiling the model** - defining the loss function(basically telling how wrong our model is) and using optimizer which tells us how o improve the patterns, and use evaluation metrics (what can we use to interpret our model)\n",
        "4. Fitting the model - letting the model try to find the patterns between X and y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1SniuLIrUhk",
        "outputId": "436c9e08-36bd-41c0-f0d6-0463a5db6bd1"
      },
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model using sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "#2.Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, #mean absolute error)\n",
        "              optimizer=tf.keras.optimizers.SGD(), # sgd stands for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "#3.Fit the model\n",
        "model.fit(X, y, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 637ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5ee3a29d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsJStRmW5SL6",
        "outputId": "62dc5206-8a66-4406-e863-75d7e4bad13d"
      },
      "source": [
        "#check x and y \n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6igcfdh8myb",
        "outputId": "0f6d8e24-7181-4947-b0f8-e1dd9223a950"
      },
      "source": [
        "# Try and make predict using our model \n",
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7USwDrt8wsR"
      },
      "source": [
        "##improving our model\n",
        "\n",
        "We can improve the model by altering the steps we used to create the model\n",
        "\n",
        "1. **Creating the model** - here we might add more layers, increase the number of hidden units (called neurons) within each of the layers, change the activation function of each layer.\n",
        "2. **Compiling the model** - here we might change the optimzation function or perhaps the **learning rate** of the optimization function. \n",
        "3. **Fitting the model** - here we might fit the model for more epochs(perhaps leave it training for longer) or more data(give the model more examples to learn from )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJeujUpOCB9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9220a79-312a-451a-a833-842673cff70f"
      },
      "source": [
        "# Lets rebuild our model\n",
        "\n",
        "#Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5ea6519d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh_n1YkdOJxm",
        "outputId": "83d4cdcf-9603-495e-ab5e-bfc169425644"
      },
      "source": [
        "#Lets see if the prediction is improved\n",
        "model.predict([17.0]) # it should  be in the same format of our data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VBr6E4KOg8o",
        "outputId": "4bc747a7-5fd3-40fc-845d-4950fa026d75"
      },
      "source": [
        "# Lets improve the model by adding extra hidden units\n",
        "\n",
        "#Create the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "         tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "         tf.keras.layers.Dense(1)                    \n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#Fit the model\n",
        "\n",
        "model.fit(X, y, epochs=100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 12.3193 - mae: 12.3193\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7804 - mae: 11.7804\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.2324 - mae: 11.2324\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6601 - mae: 10.6601\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0632 - mae: 10.0632\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4503 - mae: 9.4503\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7991 - mae: 8.7991\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1072 - mae: 8.1072\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3691 - mae: 7.3691\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5758 - mae: 6.5758\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7205 - mae: 5.7205\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7947 - mae: 4.7947\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3581 - mae: 4.3581\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3134 - mae: 4.3134\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2550 - mae: 4.2550\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2442 - mae: 4.2442\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1520 - mae: 4.1520\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1739 - mae: 4.1739\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0681 - mae: 4.0681\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0807 - mae: 4.0807\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9954 - mae: 3.9954\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9739 - mae: 3.9739\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9208 - mae: 3.9208\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9047 - mae: 3.9047\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9267 - mae: 3.9267\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8797 - mae: 3.8797\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9341 - mae: 3.9341\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8678 - mae: 3.8678\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9274 - mae: 3.9274\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8751 - mae: 3.8751\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9080 - mae: 3.9080\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8893 - mae: 3.8893\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8834 - mae: 3.8834\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8386 - mae: 3.8386\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9054 - mae: 3.9054\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8482 - mae: 3.8482\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8862 - mae: 3.8862\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8605 - mae: 3.8605\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8608 - mae: 3.8608\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8683 - mae: 3.8683\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8762 - mae: 3.8762\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8106 - mae: 3.8106\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8821 - mae: 3.8821\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8234 - mae: 3.8234\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8626 - mae: 3.8626\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8328 - mae: 3.8328\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8369 - mae: 3.8369\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8408 - mae: 3.8408\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8489 - mae: 3.8489\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7850 - mae: 3.7850\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8585 - mae: 3.8585\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7982 - mae: 3.7982\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8377 - mae: 3.8377\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8062 - mae: 3.8062\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8117 - mae: 3.8117\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8144 - mae: 3.8144\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7856 - mae: 3.7856\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8227 - mae: 3.8227\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7593 - mae: 3.7593\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7725 - mae: 3.7725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8115 - mae: 3.8115\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7807 - mae: 3.7807\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7853 - mae: 3.7853\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7891 - mae: 3.7891\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7588 - mae: 3.7588\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7975 - mae: 3.7975\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7337 - mae: 3.7337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8105 - mae: 3.8105\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7478 - mae: 3.7478\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7840 - mae: 3.7840\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7563 - mae: 3.7563\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7575 - mae: 3.7575\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7648 - mae: 3.7648\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7307 - mae: 3.7307\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7735 - mae: 3.7735\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7125 - mae: 3.7125\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7820 - mae: 3.7820\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7242 - mae: 3.7242\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7552 - mae: 3.7552\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7329 - mae: 3.7329\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7284 - mae: 3.7284\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7416 - mae: 3.7416\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7013 - mae: 3.7013\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.6921 - mae: 3.6921\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7522 - mae: 3.7522\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7016 - mae: 3.7016\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7251 - mae: 3.7251\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7105 - mae: 3.7105\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6979 - mae: 3.6979\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7194 - mae: 3.7194\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6705 - mae: 3.6705\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7299 - mae: 3.7299\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.6711 - mae: 3.6711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5e7becb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTlpYft8bV8V",
        "outputId": "309ee48c-6024-4191-b012-5a01db5db6b2"
      },
      "source": [
        "# Remind yourself of the data\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIOjYgxybqVd",
        "outputId": "a559825b-5b3d-4a52-808d-43f8b9247bc7"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.223137]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUAFg7Nsh6Fs"
      },
      "source": [
        "#Common ways to improve a deep model :\n",
        "1. Adding layers\n",
        "2. Increase the number of hidden units\n",
        "3. Change the activation functions\n",
        "4. Change the optimization functions\n",
        "5. Change the learning rate --> Very important\n",
        "6. Fitting on more data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dUGUcpwjwt6"
      },
      "source": [
        "#Evaluating a model's performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-cQ8URcj454"
      },
      "source": [
        "## The typical workflow you will go through while evaluating a model is :\n",
        "````Build a model --> fit the model -->evaluate the model --> tweak the model --> fit the model --> evalaute the model -->tweak the model -->fit the model.... ````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wxnpjiroyOQ"
      },
      "source": [
        "#When it comes to evaluation there 3 things that you should keep in mind \n",
        "\n",
        "> Visualize, visualize, visualize\n",
        "\n",
        "*What data are working with ? What does it look likee ?\n",
        "* What does our model look like ?\n",
        "* How does our model perform while training it\n",
        "* The predictions of the model - how do the predictions of the model line up against the ground truth (the original table)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkazTCj3soRl",
        "outputId": "51cd1c2e-9347-4c66-bcaa-e179b6a4bb99"
      },
      "source": [
        "#Make a larger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FeMonO-teUF",
        "outputId": "96f8c8b9-6f28-4415-db2f-51e5f69c6135"
      },
      "source": [
        "# Make lables for the dataset \n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "A1rbr9VNtnCg",
        "outputId": "361fedae-bbdb-45c7-c9ea-a8ae83772b39"
      },
      "source": [
        "#Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc5e5d76b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9CdntdGt1qp"
      },
      "source": [
        "### The 3 sets\n",
        "1. training set - the model learns from it and its typically 70-80% of the data you have\n",
        "2. Validation set - The model gets tuned on this data which is typically 10-15% of the data available\n",
        "3. Test set - Model gets evaluated on this one to test what it has learned. This is 10-15% of the total data available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOa1tPfxH2_F",
        "outputId": "e41e9175-18ee-448d-9590-f5af227012fb"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy8WzqnJCBHQ",
        "outputId": "675ccb3a-0313-4977-e0f7-3bdeaa09a373"
      },
      "source": [
        "# Split the data into test and train sets\n",
        "X_train = X[:40] # first 40 are training samples which is 80% of the data\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test= X[40:] # last 10 testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "p5T3480VC7_A",
        "outputId": "15f23200-59c9-4ab4-a4e9-f79128e82b0c"
      },
      "source": [
        "plt.figure(figsize = (10,7))\n",
        "#Plot training data in blue\n",
        "plt.scatter(X_train,y_train, c=\"b\", label=\"Training data\")\n",
        "#Plot testing data in green\n",
        "plt.scatter(X_test,y_test, c=\"g\", label=\"Test data\")\n",
        "#show a legend\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds5rIHu9HMPe"
      },
      "source": [
        "# Lets create the neural network for this model \n",
        "\n",
        "#Create the model \n",
        "model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#fit the model \n",
        "#model.fit(X_train,y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "xzLwl8_CKCsj",
        "outputId": "e6b4b53a-177f-43d4-9cb4-ffa7148dc560"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2475\u001b[0m     \"\"\"\n\u001b[1;32m   2476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2478\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba-w_sPqKJH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "fa0f58bb-ba39-443f-fa6d-75830c6ea148"
      },
      "source": [
        "model.build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2f52417d930d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must provide an `input_shape` argument.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph_network_for_inferred_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You must provide an `input_shape` argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nDlsiCRKMq4"
      },
      "source": [
        "#lets create the model which builds automatically by defining the input_shape argument \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#Create the model\n",
        "model= tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10,input_shape=[1],name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1,name=\"output_layer\")      \n",
        "], name=\"model_1\")\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckysJ4dlciQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "18440f7f-3c5c-493b-88c6-64a29de80643"
      },
      "source": [
        "Demodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0350b6cbb87d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Demodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t256mvhMcjmq"
      },
      "source": [
        "##Total params - total number of parameters in the model\n",
        "##Trainable parameters - these are the parameters that the model can update as it trains (patterns)\n",
        "##Non-trainable paramters - They are not updated during trainig. This is typical when you have parameters from other models during transfer learning) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5anvDGDoeKel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828c51cf-a578-4ea1-9298-a39e53b008ad"
      },
      "source": [
        "#Lets fit our model with training data\n",
        "\n",
        "model.fit(X_train, y_train,epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.2277 - mae: 20.2277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5e5bcd050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqZb8QXQtKPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "876003ea-efae-4f59-8287-e71d8475393b"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_sytl25vD9b"
      },
      "source": [
        "#Visualizing our model's predictions\n",
        "To visualize model, its a good idea to plot them against the ground truth \n",
        "\n",
        "Often the y_test or y_true are plotted against y_preds (grouth truth vs model's prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVWSzuYs1aOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c654db9-ccf6-4c3d-d3e7-e476800ec5b9"
      },
      "source": [
        "#making predictions\n",
        "y_preds = model.predict(X_test)\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNCH04AB1ko6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18ce88f-7797-45b7-c298-563dd2eeb716"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wee3xcZ_1nKR"
      },
      "source": [
        "# Creating a plotting function\n",
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data= X_test,\n",
        "                     test_labels= y_test,\n",
        "                     predictions= y_preds):\n",
        "\n",
        "#Plots training and test data and compares ground truth to predictions\n",
        "  plt.figure(figsize= (10, 7))\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  plt.scatter(test_data, test_labels ,c=\"g\", label=\"Test data\")\n",
        "  plt.scatter(test_data,predictions, c=\"r\", label=\"Predictions\")\n",
        "\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2nR9IiQ4SfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "44a3a5c6-291a-4e73-bb7d-0e8196348636"
      },
      "source": [
        "plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data= X_test,\n",
        "                     test_labels= y_test,\n",
        "                     predictions= y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVEnd-TD5WXm"
      },
      "source": [
        "#Evaluating our model's predictiion with regression evalaution metrics\n",
        "\n",
        "* MAE - mean absolute error, on average how wrong is each of the model's predictions\n",
        "* MSE - mean square error, sqaure the average errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPZRfTA3GJg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fb3f98-2849-4cbd-9f3c-020fbd4c27bd"
      },
      "source": [
        "#Evalaute the model \n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 130ms/step - loss: 3.1969 - mae: 3.1969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196942090988159, 3.196942090988159]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hTXEP2HGOVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6965fc-aee2-433f-ede9-142c4dc17b49"
      },
      "source": [
        "#Calculate mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                      y_pred=tf.constant(y_preds))\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD3QtvS_NHJs"
      },
      "source": [
        "#MSE should be single output but here we see many outputs. This is because y_preds and y_test are of different shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxdsBKOlI27P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e14eb5b-4b89-44a2-bd88-7e065c4fde9a"
      },
      "source": [
        "\n",
        "tf.constant(y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtepoht6JN8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25780ec5-444f-4eb7-c684-084d61a486d7"
      },
      "source": [
        "y_test.shape, y_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10]), (10, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWzR2jBCNV6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8e91cd-9439-46c7-a88c-42fdd3cafd07"
      },
      "source": [
        "y_preds.squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
              "        93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8-fuZkNZlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34bb2d3-dc7d-4b78-b2da-345b43656ad0"
      },
      "source": [
        "y_test.shape, y_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10]), (10, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cechyTf5Nbau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd5537a-ef00-4c2f-f08e-5ea19f861edc"
      },
      "source": [
        "\n",
        "y_preds.squeeze().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj-LU7mSNzZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc33845-6bf2-4798-eccf-6ef02de33bc3"
      },
      "source": [
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=y_preds.squeeze())\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a5lS2T8ONXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2157cdce-7eee-4daa-ae95-909d8cc114fa"
      },
      "source": [
        "#Calcualte mean square error\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                    y_pred=y_preds.squeeze())\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XwJbbWnOrUK"
      },
      "source": [
        "#Running experiments to improve a model \n",
        "\n",
        "After looking at evaulation metrics and predictions of the models , there is a chance that u will improve it "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PDWBf5efOy_"
      },
      "source": [
        "# You can do this by 3 ways\n",
        "* Get more data\n",
        "* Make more complex model - by making it larger by adding more layers and more hidden units\n",
        "* Train for longer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYoSulaffiHp"
      },
      "source": [
        "#build model_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zsG2nnmfmIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa34f3a2-f61f-4dcd-c9b2-26d7bf1b25e4"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7067 - mae: 8.7067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5ea67ca10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulxBG6xf4oa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "77d4ea1d-9790-4fca-9c78-5649a8f9a752"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc5ead0b830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3xU9Z3v8fcHRDTAImKqCE0Cvf4AFANkUeuKUBSp1io+ai82rlrrIl4t1X24auWxFfc+0ke1tnJx70rjrq22ser1R/1R7Soom95F1wbNDb+0UE0Qy2LENuIGlR+f+8dM4hAmYSZz5sc55/V8PPJI5szMOd/MTPDt95zzPubuAgAAQHAGFHsAAAAAUUPAAgAACBgBCwAAIGAELAAAgIARsAAAAAJ2ULEHkOqII47wqqqqYg8DAADggFavXv2+u5enu6+kAlZVVZWampqKPQwAAIADMrO23u5jFyEAAEDACFgAAAABI2ABAAAErKSOwUpn165d2rJliz7++ONiDwVJhxxyiMaMGaNBgwYVeygAAJSkkg9YW7Zs0bBhw1RVVSUzK/ZwYs/dtX37dm3ZskVjx44t9nAAAChJJb+L8OOPP9bIkSMJVyXCzDRy5EhmFAEA6EPJByxJhKsSw/sBAEDfQhGwAAAAwoSAdQDbt29XdXW1qqurddRRR2n06NHdtz/99NM+n9vU1KSFCxcecBtf/OIXgxruPmbMmHHA4tYlS5aos7MzL9sHACCuSv4g92IbOXKkmpubJUmLFy/W0KFDdcMNN3Tfv3v3bh10UPqXsaamRjU1NQfcxqpVq4IZbD8sWbJEl1xyicrKyoo2BgAAoiZyM1gNDVJVlTRgQOJ7Q0Pw27j88su1YMECnXzyybrxxhv16quv6tRTT9XkyZP1xS9+UW+++aYkaeXKlfrKV74iKRHOrrjiCs2YMUPjxo3T0qVLu9c3dOjQ7sfPmDFDX/va13T88certrZW7i5JevbZZ3X88cdr6tSpWrhwYfd6U+3cuVPz5s3T+PHjNXfuXO3cubP7vquvvlo1NTWaOHGibr31VknS0qVL9cc//lEzZ87UzJkze30cAADITqRmsBoapPnzpa49Xm1tiduSVFsb7La2bNmiVatWaeDAgfrwww/129/+VgcddJCWL1+uW265RY899th+z3njjTf00ksvaceOHTruuON09dVX79cl9frrr2vdunU6+uijddppp+nf//3fVVNTo6uuukqNjY0aO3asLr744rRjuueee1RWVqYNGzaopaVFU6ZM6b6vrq5Ohx9+uPbs2aNZs2appaVFCxcu1I9//GO99NJLOuKII3p93KRJkwJ85QAAiL5IzWAtWvRZuOrS2ZlYHrSLLrpIAwcOlCR1dHTooosu0gknnKDrr79e69atS/ucc889V4MHD9YRRxyhz33uc9q2bdt+j5k2bZrGjBmjAQMGqLq6Wq2trXrjjTc0bty47t6p3gJWY2OjLrnkEknSpEmT9glGjzzyiKZMmaLJkydr3bp1Wr9+fdp1ZPo4AADQu0gFrM2bs1ueiyFDhnT//Pd///eaOXOm1q5dq6effrrXjqjBgwd3/zxw4EDt3r27X4/J1ttvv60777xTK1asUEtLi84999y0Y8z0cQAAlKqGNQ2qWlKlAbcNUNWSKjWsycOxQhmIVMCqqMhueVA6Ojo0evRoSdLPfvazwNd/3HHH6a233lJra6sk6eGHH077uOnTp+vBBx+UJK1du1YtLS2SpA8//FBDhgzR8OHDtW3bNj333HPdzxk2bJh27NhxwMcBAFDqGtY0aP7T89XW0SaXq62jTfOfnl+UkBWpgFVXJ/U8Ga6sLLE8n2688UZ997vf1eTJkwOZcerp0EMP1T/90z9pzpw5mjp1qoYNG6bhw4fv97irr75aH330kcaPH6/vfe97mjp1qiTppJNO0uTJk3X88cfrG9/4hk477bTu58yfP19z5szRzJkz+3wcAAClbtGKRercte+xQp27OrVoRR6OFToA6zpLrRTU1NR4z96mDRs2aPz48Rmvo6EhcczV5s2Jmau6uuAPcC+Gjz76SEOHDpW765prrtExxxyj66+/vmjjyfZ9AQAg3wbcNkCu/XONybT31r2Bb8/MVrt72j6mSM1gSYkw1doq7d2b+B6FcCVJ9957r6qrqzVx4kR1dHToqquuKvaQAAAoKRXD0x8T1NvyfIpcwIqq66+/Xs3NzVq/fr0aGhooBgUAoIe6WXUqG7Tvfx/LBpWpblaejxVKg4AFAAAiofbEWtWfV6/K4ZUymSqHV6r+vHrVnlj43VmRKhoFAADR1LCmQYtWLNLmjs2qGF6hull1aYNT7Ym1RQlUPRGwAABASeuqX+g6Q7CrfkFSSYSpdNhFCAAASlop1S9kKquAZWb3mdl7ZrY2ZdnhZvaCmW1Mfh+RXG5mttTMNplZi5lN6X3NpWv79u2qrq5WdXW1jjrqKI0ePbr79qeffnrA569cuVKrVq3KaFtVVVV6//33+3zM97///YzWBQBAVGzuSH9Jlt6Wl4JsZ7B+JmlOj2U3S1rh7sdIWpG8LUlflnRM8mu+pHv6P8ziGTlypJqbm9Xc3KwFCxZ0n83X3Nysgw8++IDPzyZgZYKABQCIm1KqX8hUVgHL3RslfdBj8fmS7k/+fL+kC1KWP+AJr0g6zMxG5TLYTBTiGkSrV6/WGWecoalTp+rss8/W1q1bJUlLly7VhAkTNGnSJM2bN0+tra1atmyZ7rrrLlVXV+u3v/3tPuvZvn27Zs+erYkTJ+rKK69UaunrBRdcoKlTp2rixImqr6+XJN18883auXOnqqurVZss+Er3OAAAoqSU6hcy5u5ZfUmqkrQ25fafU362rtuSnpH0Vyn3rZBUk2Z98yU1SWqqqKjwntavX7/fst78ouUXXlZX5lqs7q+yujL/RcsvMl5HX2699Va/4447/NRTT/X33nvP3d0feugh/+Y3v+nu7qNGjfKPP/7Y3d3/9Kc/dT/nhz/8Ydr1ffvb3/bbbrvN3d2feeYZl+Tt7e3u7r59+3Z3d+/s7PSJEyf6+++/7+7uQ4YM2WcdvT0u37J5XwAAyNUvWn7hlXdVui02r7yrMrD/tudCUpP3kpcCPYvQ3d3Msrr2jrvXS6qXEpfKyWX7fR0EF9RZBp988onWrl2rs846S5K0Z88ejRqVmJibNGmSamtrdcEFF+iCCy7oazWSpMbGRj3++OOSpHPPPVcjRozovm/p0qV64oknJEnvvPOONm7cqJEjR+63jkwfBwBAqcm0ekEqnfqFTAURsLaZ2Sh335rcBfhecvm7kj6f8rgxyWV5U4iD4NxdEydO1Msvv7zffb/+9a/V2Niop59+WnV1dVqzZk2/trFy5UotX75cL7/8ssrKyjRjxgx9/PHH/X4cAAClJozVC9kIoqbhKUmXJX++TNKTKcsvTZ5NeIqkDnffGsD2elWIg+AGDx6s9vb27oC1a9curVu3Tnv37tU777yjmTNn6vbbb1dHR4c++ugjDRs2TDt27Ei7runTp+vBBx+UJD333HP605/+JEnq6OjQiBEjVFZWpjfeeEOvvPJK93MGDRqkXbt2HfBxAACUsjBWL2Qj25qGX0p6WdJxZrbFzL4l6QeSzjKzjZLOTN6WpGclvSVpk6R7Jf2PwEbdi0IcBDdgwAA9+uijuummm3TSSSepurpaq1at0p49e3TJJZfoxBNP1OTJk7Vw4UIddthhOu+88/TEE0+kPcj91ltvVWNjoyZOnKjHH39cFRWJIDhnzhzt3r1b48eP180336xTTjml+znz58/v3hXZ1+MAAChlYaxeyIa553TYU6Bqamq8qalpn2UbNmzQ+PHjM15HNvtz0X/Zvi8AAKSqWlKlto62/ZZXDq9U63WthR9QP5jZanevSXdf5C6VE7aD4AAAiKO6WXX7HIMlhaB6IQtcKgcAABRc7Ym1qj+vXpXDK2UyVQ6vVP159ZGZJIncDBYAACiuTA/XifJeJwIWAAAITNTrFzLFLkIAABCYqNcvZIqABQAAAhP1+oVMEbAyMHDgQFVXV+uEE07QRRddpM7OzgM/qReXX365Hn30UUnSlVdeqfXr1/f62JUrV2rVqlXdt5ctW6YHHnig39sGACDfClH6HQYErAwceuiham5u1tq1a3XwwQdr2bJl+9y/e/fufq33n//5nzVhwoRe7+8ZsBYsWKBLL720X9sCAKAQClH6HQbRC1gNDVJVlTRgQOJ7Q0Ogqz/99NO1adMmrVy5Uqeffrq++tWvasKECdqzZ4/+7u/+Tn/5l3+pSZMm6Sc/+YmkxLULr732Wh133HE688wz9d5773Wva8aMGeoqVv3Nb36jKVOm6KSTTtKsWbPU2tqqZcuW6a677upugV+8eLHuvPNOSVJzc7NOOeUUTZo0SXPnzu2+zM6MGTN00003adq0aTr22GO72+PXrVunadOmqbq6WpMmTdLGjRsDfV0AAJCiX7+QqWidRdjQIM2fL3XtwmtrS9yWpNrc39jdu3frueee05w5cyRJr732mtauXauxY8eqvr5ew4cP1+9+9zt98sknOu200zR79my9/vrrevPNN7V+/Xpt27ZNEyZM0BVXXLHPetvb2/U3f/M3amxs1NixY/XBBx/o8MMP14IFCzR06FDdcMMNkqQVK1Z0P+fSSy/V3XffrTPOOEPf+973dNttt2nJkiXd43z11Vf17LPP6rbbbtPy5cu1bNkyfec731Ftba0+/fRT7dmzJ+fXAwAQL9QvZC5aM1iLFn0Wrrp0diaW52Dnzp2qrq5WTU2NKioq9K1vfUuSNG3aNI0dO1aS9Pzzz+uBBx5QdXW1Tj75ZG3fvl0bN25UY2OjLr74Yg0cOFBHH320vvSlL+23/ldeeUXTp0/vXtfhhx/e53g6Ojr05z//WWeccYYk6bLLLlNjY2P3/RdeeKEkaerUqWptbZUknXrqqfr+97+v22+/XW1tbTr00ENzek0AAPHSVb/Q1tEml3fXLzSsCXZPUVREK2Bt7uUMhd6WZ6jrGKzm5mbdfffdOvjggyVJQ4YM6X6Mu+vuu+/uftzbb7+t2bNn57Td/ho8eLCkxMH5XceHfeMb39BTTz2lQw89VOecc45efPHFoowNABBO1C9kJ1oBq6KXMxR6Wx6gs88+W/fcc4927dolSfr973+v//qv/9L06dP18MMPa8+ePdq6dateeuml/Z57yimnqLGxUW+//bYk6YMPPpAkDRs2TDt27Njv8cOHD9eIESO6j6/6+c9/3j2b1Zu33npL48aN08KFC3X++eerpaUlp98XABAv1C9kJ1rHYNXV7XsMliSVlSWW59mVV16p1tZWTZkyRe6u8vJy/epXv9LcuXP14osvasKECaqoqNCpp56633PLy8tVX1+vCy+8UHv37tXnPvc5vfDCCzrvvPP0ta99TU8++aTuvvvufZ5z//33a8GCBers7NS4ceP005/+tM/xPfLII/r5z3+uQYMG6aijjtItt9wS6O8PAIi2iuEVautoS7sc+zN3L/YYutXU1HjXWXVdNmzYoPHjx2e+koaGxDFXmzcnZq7q6gI5wB37yvp9AQCEWs9L4EiJ+oU4niHYxcxWu3tNuvuiNYMlJcIUgQoAgEB1hahMziJEFAMWAADIWKbVCxL1C9kIRcByd5lZsYeBpFLarQwA6L+eu/26qhckEaRyVPJnER5yyCHavn07/1EvEe6u7du365BDDin2UAAAOYpk9UKer+iSqZKfwRozZoy2bNmi9vb2Yg8FSYcccojGjBlT7GEAAHIUueqFPF/RJRslH7AGDRrU3XAOAACCE7nqhb6u6FLggFXyuwgBAEB+1M2qU9mgsn2WlQ0qU92s/PdH5kWerujSHwQsAABiqvbEWtWfV6/K4ZUymSqHV4a716qIV3TpiYAFAEAENaxpUNWSKg24bYCqllT1elHm2hNr1Xpdq/beulet17WGN1xJiXLxsn1n5Ap1RZeeCFgAAERMV/1CW0ebXN5dv9BbyAqFTM4OrK2V6uulykrJLPG9vr4oBeQlf6kcAACQnaolVWkPXq8cXqnW61oLP6Bc9Tw7UErMTBUpPHXp61I5zGABABAxkatf6OvswBJFwAIAIGJ6q1kIbf1CCZ0dmCkCFgAAERO5+oUSOjswUwQsAAAiJnL1CyV0dmCmCFgAAIREptULUkjqFzK9bmAJnR2YKc4iBAAgBLqqF1Ivzlw2qCy8M1MlemZgNvo6i5CABQBACESueqGqKnEx5p4qK6XW1kKPpl+oaQAAIOQiV70QwjMDs0HAAgAgBCJXvRDCMwOzkXPAMrPjzKw55etDM7vOzBab2bspy88JYsAAAMRR5KoXQnhmYDZyDlju/qa7V7t7taSpkjolPZG8+66u+9z92Vy3BQBAXIWqeiFk1w3Mh0APcjez2ZJudffTzGyxpI/c/c5Mn89B7gCAOGpY06BFKxZpc8dmVQyvUN2sutIMTpmIwNmBmSrkQe7zJP0y5fa1ZtZiZveZ2YheBjffzJrMrKm9vT3g4QAAUNq66hfaOtrkcrV1tGn+0/P77LgqaSG8bmA+BDaDZWYHS/qjpInuvs3MjpT0viSX9D8ljXL3K/paBzNYAIC4iVz9woABUrpsYSbt3Vv48eRRoWawvizpNXffJknuvs3d97j7Xkn3SpoW4LYAAIiEyNUvRPzswEwFGbAuVsruQTMblXLfXElrA9wWAACRELn6hYifHZipQAKWmQ2RdJakx1MW32Fma8ysRdJMSdcHsS0AAKIkVPULnB2YMS6VAwBAkYXiLMIYnR2YKa5FCABAEYQiOGUqAtcODFpfAeugQg8GAIA46Kpf6NyVmPHpql+QFM6QFfFrBwaNaxECAJAHi1Ys6g5XXTp3dWrRipD2QXF2YFYIWAAA5EHk6hc4OzArBCwAAPIgcvULnB2YFQIWAAB5EJr6hUyqF7rU1iYOaN+7N/GdcNUrAhYAAHlQe2Kt6s+rV+XwSplMlcMrVX9efWkd4N5VvdDWlri8TVtb4nZfIQsZoaYBAIAsNDQkrlu8eXPi+O66uhBP5FC9kBNqGgAACEDPrs2uCR8ppCGL6oW8YRchAAAZWrRo3yJzKXF7UUibF6heyB8CFgAAGYrchA/VC3lDwAIAIEOhmvDhwsxFRcACACBDoZnwyebsQKoX8oKABQBAhkIz4RO5g8XCh4AFAIAy79sMxYRP5A4WCx8CFgAg9iLXtxmqg8WiiYAFAIi9yO1RC83BYtFFwAIAxF5o9qhlsx8zFAeLRRdN7gCA2KuoSH/FmJLao5ZtjXxtLYGqiJjBAgDEXij2qEVuP2a0EbAAALEXij1qodmPCYmABQCIuMjUL3BmYKgQsAAAkRWp+oVQ7MdEFwIWACCyQnPYEtcNjBxz92KPoVtNTY03NTUVexgAgIgYMCAxc9WTWWJXYEnoeXaglJiZIjyVPDNb7e416e5jBgsAEFmhOGwpNNNsyAYBCwAQWaE4bImzAyOJgAUAiKxQHLYUimk2ZIuABQAInUyrF6QQ1C+EYpoN2SJgAQBCJVTVC5wdGFucRQgACJWqqvTXDaysTMxQlQzODow8ziIEAERGaI4J5+zAWCNgAQBCJTTHhIcmCSIfCFgAgFAJzTHhoUmCyAcCFgAgVEJzTHhokiDyIbCAZWatZrbGzJrNrCm57HAze8HMNia/jwhqewCA6Mm0fqHkqxekECVB5ENgZxGaWaukGnd/P2XZHZI+cPcfmNnNkka4+029rYOzCAEgvjjpDmFTzLMIz5d0f/Ln+yVdkOftAQBCipPuECVBBiyX9LyZrTaz+cllR7r71uTP/ynpyJ5PMrP5ZtZkZk3t7e0BDgcAECacdIcoCTJg/ZW7T5H0ZUnXmNn01Ds9sS9yv/2R7l7v7jXuXlNeXh7gcAAAYcJJd4iSwAKWu7+b/P6epCckTZO0zcxGSVLy+3tBbQ8AEC2cdIcoCSRgmdkQMxvW9bOk2ZLWSnpK0mXJh10m6ckgtgcAiB5OukOUBDWDdaSk/2tm/0/Sq5J+7e6/kfQDSWeZ2UZJZyZvAwBiJlL1C0AGDgpiJe7+lqST0izfLmlWENsAAIRTz/qFtrbEbYkAheiiyR0AkFfULyCOCFgAgLyifgFxRMACAOQV9QuIIwIWACCvqF9AHBGwAAB5Rf0C4iiQswgBAOhLbS2BCvHCDBYAoF8y7bYC4ogZLABA1ui2AvrGDBYAIGt0WwF9I2ABALJGtxXQNwIWACBrdFsBfSNgAQCyRrcV0DcCFgAga3RbAX0jYAEA9pFp/UJtrdTaKu3dm/hOuAI+Q00DAKAb9QtAMJjBAgB0o34BCAYBCwDQjfoFIBgELABAN+oXgGAQsAAA3ahfAIJBwAIAdKN+AQgGAQsAYoL6BaBwqGkAgBigfgEoLGawACAGqF8ACouABQAxQP0CUFgELACIAeoXgMIiYAFADFC/ABQWAQsAYoD6BaCwCFgAEGKZVi9I1C8AhURNAwCEFNULQOliBgsAQorqBaB0EbAAIKSoXgBKFwELAEKK6gWgdBGwACCkqF4AShcBCwBCiuoFoHQRsACgBGVav0D1AlCacg5YZvZ5M3vJzNab2Toz+05y+WIze9fMmpNf5+Q+XACIvq76hbY2yf2z+oW+Oq4AlBZz99xWYDZK0ih3f83MhklaLekCSV+X9JG735npumpqarypqSmn8QBA2FVVJUJVT5WViVkqAKXBzFa7e026+3IuGnX3rZK2Jn/eYWYbJI3Odb0AEFfULwDhF+gxWGZWJWmypP9ILrrWzFrM7D4zGxHktgAgqqhfAMIvsIBlZkMlPSbpOnf/UNI9kr4gqVqJGa4f9fK8+WbWZGZN7e3tQQ0HAEKL+gUg/AIJWGY2SIlw1eDuj0uSu29z9z3uvlfSvZKmpXuuu9e7e42715SXlwcxHAAINeoXgPAL4ixCk/Qvkja4+49Tlo9KedhcSWtz3RYAhB31C0A85HyQu6TTJP21pDVm1pxcdouki82sWpJLapV0VQDbAoDQ6qpf6LpAc1f9gkSAAqIm55qGIFHTACDKqF8AoqWvmgaa3AGgQKhfAOKDgAUABUL9AhAfBCwAKBDqF4D4IGABQIFQvwDEBwELAHKUafWCRP0CEBdB1DQAQGxRvQAgHWawACAHixZ9Fq66dHYmlgOILwIWAOSA6gUA6RCwACAHVC8ASIeABQA5oHoBQDoELADIAdULANIhYAFALzKtX6B6AUBP1DQAQBrULwDIBTNYAJAG9QsAckHAAoA0qF8AkAsCFgCkQf0CgFwQsAAgDeoXAOSCgAUAaVC/ACAXBCwAsUP9AoB8o6YBQKxQvwCgEJjBAhAr1C8AKAQCFoBYoX4BQCEQsADECvULAAqBgAUgVqhfAFAIBCwAsUL9AoBCIGABiIRMqxck6hcA5B81DQBCj+oFAKWGGSwAoUf1AoBSQ8ACEHpULwAoNQQsAKFH9QKAUkPAAhB6VC8AKDUELAChR/UCgFJDwAJQ0jKtX6B6AUApoaYBQMmifgFAWDGDBaBkUb8AIKwIWABKFvULAMIq7wHLzOaY2ZtmtsnMbs739gBEB/ULAMIqrwHLzAZK+t+SvixpgqSLzWxCPrcJIDqoXwAQVvmewZomaZO7v+Xun0p6SNL5ed4mgIigfgFAWOU7YI2W9E7K7S3JZd3MbL6ZNZlZU3t7e56HA6AUZFq9IFG/ACCcin6Qu7vXu3uNu9eUl5cXezgA8qyreqGtTXL/rHqhr5AFAGGT74D1rqTPp9wek1wGIKaoXgAQB/kOWL+TdIyZjTWzgyXNk/RUnrcJoIRRvQAgDvIasNx9t6RrJf2rpA2SHnH3dfncJoDSRvUCgDjI+zFY7v6sux/r7l9wd06uBmKO6gUAcVD0g9wBxAvVCwDigIAFIDCZ1i9QvQAg6g4q9gAARENX/ULXGYJd9QsSAQpA/DCDBSAQ1C8AwGcIWAACQf0CAHyGgAUgENQvAMBnCFgAAkH9AgB8hoAFIBDULwDAZwhYAA6I+gUAyA41DQD6RP0CAGSPGSwAfaJ+AQCyR8AC0CfqFwAgewQsAH2ifgEAskfAAtAn6hcAIHsELAB9on4BALJHwAJiKtPqBYn6BQDIFjUNQAxRvQAA+cUMFhBDVC8AQH4RsIAYonoBAPKLgAXEENULAJBfBCwghqheAID8ImABMUT1AgDkFwELiJhM6xeoXgCA/KGmAYgQ6hcAoDQwgwVECPULAFAaCFhAhFC/AAClgYAFRAj1CwBQGghYQIRQvwAApYGABUQI9QsAUBoIWEBIUL8AAOFBTQMQAtQvAEC4MIMFhAD1CwAQLgQsIASoXwCAcCFgASFA/QIAhAsBCwgB6hcAIFxyClhm9kMze8PMWszsCTM7LLm8ysx2mllz8mtZMMMF4on6BQAIF3P3/j/ZbLakF919t5ndLknufpOZVUl6xt1PyGZ9NTU13tTU1O/xAAAAFIqZrXb3mnT35TSD5e7Pu/vu5M1XJI3JZX1A3GTabQUACJcgj8G6QtJzKbfHmtnrZvZvZnZ6b08ys/lm1mRmTe3t7QEOByhtXd1WbW2S+2fdVoQsAAi/A+4iNLPlko5Kc9cid38y+ZhFkmokXejubmaDJQ119+1mNlXSryRNdPcP+9oWuwgRJ1VViVDVU2VlooEdAFDa+tpFeMAmd3c/8wArv1zSVyTN8mRac/dPJH2S/Hm1mf1B0rGSSE9AEt1WABBduZ5FOEfSjZK+6u6dKcvLzWxg8udxko6R9FYu2wKihm4rAIiuXI/B+kdJwyS90KOOYbqkFjNrlvSopAXu/kGO2wIihW4rAIiunC727O7/rZflj0l6LJd1A1HX1WG1aFFit2BFRSJc0W0FAOFHkzuQB5nWL9TWJg5o37s38Z1wBQDRkNMMFoD9ddUvdCaPSuyqX5AIUAAQF8xgAQFbtOizcNWlszOxHAAQDwQsIGDULwAACFhAwKhfAAAQsICAUb8AACBgAQGrrZXq6xOXvDFLfK+v5wB3AIgTAhaQBeoXAACZoKYByBD1CwCATDGDBWSI+gUAQKYIWECGqF8AAGSKgARRmQAAAAwfSURBVAVkiPoFAECmCFhAhqhfAABkioAFZIj6BQBApghYiL1Mqxck6hcAAJmhpgGxRvUCACAfmMFCrFG9AADIBwIWYo3qBQBAPhCwEGtULwAA8oGAhVijegEAkA8ELMQa1QsAgHwgYCGyMq1foHoBABA0ahoQSdQvAACKiRksRBL1CwCAYiJgIZKoXwAAFBMBC5FE/QIAoJgIWIgk6hcAAMVEwEIkUb8AACgmAhZCh/oFAECpo6YBoUL9AgAgDJjBQqhQvwAACAMCFkKF+gUAQBgQsBAq1C8AAMKAgIVQoX4BABAGBCyECvULAIAwyClgmdliM3vXzJqTX+ek3PddM9tkZm+a2dm5DxVRlmn1gkT9AgCg9AVR03CXu9+ZusDMJkiaJ2mipKMlLTezY919TwDbQ8RQvQAAiJp87SI8X9JD7v6Ju78taZOkaXnaFkKO6gUAQNQEEbCuNbMWM7vPzEYkl42W9E7KY7Ykl+3HzOabWZOZNbW3twcwHIQN1QsAgKg5YMAys+VmtjbN1/mS7pH0BUnVkrZK+lG2A3D3enevcfea8vLyrH8BhB/VCwCAqDngMVjufmYmKzKzeyU9k7z5rqTPp9w9JrkM2E9d3b7HYElULwAAwi3XswhHpdycK2lt8uenJM0zs8FmNlbSMZJezWVbiC6qFwAAUZPrMVh3mNkaM2uRNFPS9ZLk7uskPSJpvaTfSLqGMwjjKdP6BaoXAABRklNNg7v/dR/31UliJ0+MUb8AAIgrmtyRN9QvAADiioCFvKF+AQAQVwQs5A31CwCAuCJgIW/q6hJ1C6moXwAAxAEBC3lD/QIAIK4IWOgX6hcAAOhdTjUNiCfqFwAA6BszWMga9QsAAPSNgIWsUb8AAEDfCFjIGvULAAD0jYCFrFG/AABA3whYyBr1CwAA9I2AhW6ZVi9I1C8AANAXahogieoFAACCxAwWJFG9AABAkAhYkET1AgAAQSJgQRLVCwAABImABUlULwAAECQCFiRRvQAAQJAIWDGQaf0C1QsAAASDmoaIo34BAIDCYwYr4qhfAACg8AhYEUf9AgAAhUfAijjqFwAAKDwCVsRRvwAAQOERsCKO+gUAAAqPgBVSmVYvSNQvAABQaNQ0hBDVCwAAlDZmsEKI6gUAAEobASuEqF4AAKC0EbBCiOoFAABKGwErhKheAACgtBGwQojqBQAAShsBq8RkWr9A9QIAAKWLmoYSQv0CAADRkNMMlpk9bGbNya9WM2tOLq8ys50p9y0LZrjRRv0CAADRkNMMlrv/966fzexHkjpS7v6Du1fnsv64oX4BAIBoCOQYLDMzSV+X9Msg1hdX1C8AABANQR3kfrqkbe6+MWXZWDN73cz+zcxO7+2JZjbfzJrMrKm9vT2g4YQT9QsAAETDAQOWmS03s7Vpvs5PedjF2nf2aqukCnefLOlvJT1oZn+Rbv3uXu/uNe5eU15ensvvEnrULwAAEA0HDFjufqa7n5Dm60lJMrODJF0o6eGU53zi7tuTP6+W9AdJx+bnVwgH6hcAAIiPIGoazpT0hrtv6VpgZuWSPnD3PWY2TtIxkt4KYFuhRP0CAADxEsQxWPO0/8Ht0yW1JGsbHpW0wN0/CGBboUT9AgAA8ZLzDJa7X55m2WOSHst13VFB/QIAAPHCpXIKgPoFAADihYBVANQvAAAQLwSsAqB+AQCAeCFg5SDT6gWJ+gUAAOIkiJqGWKJ6AQAA9IYZrH6iegEAAPSGgNVPVC8AAIDeELD6ieoFAADQGwJWP1G9AAAAekPA6ieqFwAAQG8IWGlkWr9A9QIAAEiHmoYeqF8AAAC5YgarB+oXAABArghYPVC/AAAAckXA6oH6BQAAkCsCVg/ULwAAgFwRsHqgfgEAAOSKswjTqK0lUAEAgP6L1QxWpv1WAAAAuYjNDBb9VgAAoFBiM4NFvxUAACiU2AQs+q0AAEChxCZg0W8FAAAKJTYBi34rAABQKLEJWPRbAQCAQonNWYQS/VYAAKAwYjODBQAAUCgELAAAgIARsAAAAAJGwAIAAAgYAQsAACBgBCwAAICAEbAAAAACRsACAAAIGAELAAAgYAQsAACAgBGwAAAAAkbAAgAACJi5e7HH0M3M2iW1FWBTR0h6vwDbKVVx//0lXgOJ10DiNYj77y/xGki8Brn8/pXuXp7ujpIKWIViZk3uXlPscRRL3H9/iddA4jWQeA3i/vtLvAYSr0G+fn92EQIAAASMgAUAABCwuAas+mIPoMji/vtLvAYSr4HEaxD331/iNZB4DfLy+8fyGCwAAIB8iusMFgAAQN4QsAAAAAIW6YBlZheZ2Toz22tmNT3u+66ZbTKzN83s7JTlc5LLNpnZzYUfdf6Y2cNm1pz8ajWz5uTyKjPbmXLfsmKPNV/MbLGZvZvyu56Tcl/az0SUmNkPzewNM2sxsyfM7LDk8th8BqRo/533xsw+b2Yvmdn65L+L30ku7/VvImqS/+6tSf6eTcllh5vZC2a2Mfl9RLHHmS9mdlzK+9xsZh+a2XVR/wyY2X1m9p6ZrU1ZlvZ9t4SlyX8bWsxsSr+3G+VjsMxsvKS9kn4i6QZ37/qDmiDpl5KmSTpa0nJJxyaf9ntJZ0naIul3ki529/UFHnremdmPJHW4+z+YWZWkZ9z9hOKOKv/MbLGkj9z9zh7L034m3H1PwQeZR2Y2W9KL7r7bzG6XJHe/KWafgYGKyd95KjMbJWmUu79mZsMkrZZ0gaSvK83fRBSZWaukGnd/P2XZHZI+cPcfJMP2CHe/qVhjLJTk38G7kk6W9E1F+DNgZtMlfSTpga5/43p735Ph8tuSzlHitflf7n5yf7Yb6Rksd9/g7m+muet8SQ+5+yfu/rakTUr8h3WapE3u/pa7fyrpoeRjI8XMTIl/VH9Z7LGUkN4+E5Hi7s+7++7kzVckjSnmeIokFn/nPbn7Vnd/LfnzDkkbJI0u7qhKwvmS7k/+fL8SoTMOZkn6g7sX4uopReXujZI+6LG4t/f9fCWCmLv7K5IOS/7PSdYiHbD6MFrSOym3tySX9bY8ak6XtM3dN6YsG2tmr5vZv5nZ6cUaWIFcm5z6vS9ld0Bc3vtUV0h6LuV2XD4DcXyv95GcsZws6T+Si9L9TUSRS3rezFab2fzksiPdfWvy5/+UdGRxhlZw87Tv/2TH5TPQpbf3PbB/H0IfsMxsuZmtTfMV+f8jTSfD1+Ni7fuHtVVShbtPlvS3kh40s78o5LiDdIDX4B5JX5BUrcTv/aOiDjYPMvkMmNkiSbslNSQXReozgN6Z2VBJj0m6zt0/VAz+JlL8lbtPkfRlSdckdx1188QxM9E9bibJzA6W9FVJ/ye5KE6fgf3k630/KOgVFpq7n9mPp70r6fMpt8ckl6mP5aFwoNfDzA6SdKGkqSnP+UTSJ8mfV5vZH5Q4Jq0pj0PNm0w/E2Z2r6Rnkjf7+kyESgafgcslfUXSrOQ/LJH7DBxAZN7rbJnZICXCVYO7Py5J7r4t5f7Uv4nIcfd3k9/fM7MnlNhdvM3MRrn71uSuoPeKOsjC+LKk17re+zh9BlL09r4H9u9D6Gew+ukpSfPMbLCZjZV0jKRXlTjY9RgzG5tM+POSj42SMyW94e5buhaYWXnygEeZ2TglXo+3ijS+vOqxL32upK6zSnr7TESKmc2RdKOkr7p7Z8ry2HwGFI+/8/0kj738F0kb3P3HKct7+5uIFDMbkjy4X2Y2RNJsJX7XpyRdlnzYZZKeLM4IC2qfvRhx+Qz00Nv7/pSkS5NnE56ixMlgW9Ot4EBCP4PVFzObK+luSeWSfm1mze5+truvM7NHJK1XYjfJNV1ni5nZtZL+VdJASfe5+7oiDT9feu53l6Tpkv7BzHYpcdblAnfveUBgVNxhZtVKTAe3SrpKkvr6TETMP0oaLOmFxH9v9Yq7L1CMPgPJMyij/neezmmS/lrSGktWtEi6RdLF6f4mIuhISU8kP/cHSXrQ3X9jZr+T9IiZfUtSmxInAEVWMlyepX3f57T/LkaFmf1S0gxJR5jZFkm3SvqB0r/vzypxBuEmSZ1KnGHZv+1GuaYBAACgGOK6ixAAACBvCFgAAAABI2ABAAAEjIAFAAAQMAIWAABAwAhYAAAAASNgAQAABOz/A7SmR0tb/SyLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN9uS2xTgbMf"
      },
      "source": [
        "def mae(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculuates mean absolute error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_absolute_error(y_test,\n",
        "                                        y_pred)\n",
        "  \n",
        "def mse(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates mean squared error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_squared_error(y_test,\n",
        "                                       y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqlnnxw8foGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b7c2e5-7543-43c1-976a-b89f958bf42a"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()\n",
        "mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()\n",
        "mae_1, mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18.745327, 353.57336)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Pv7T8vfz0Z"
      },
      "source": [
        "#Build model_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC6S0gzPgjLk"
      },
      "source": [
        "#Just adding an extra dense layer and keeping everyting else the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l4i3x8kwtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4603bdf-fbb5-4e37-8f90-0f90517d770b"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.6625 - mae: 22.6625\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9439 - mae: 16.9439\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.8059 - mae: 13.8059\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4504 - mae: 17.4504\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0637 - mae: 12.0637\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.8335 - mae: 9.8335\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7023 - mae: 10.7023\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.8713 - mae: 10.8713\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 38.0435 - mae: 38.0435\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.6226 - mae: 25.6226\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2375 - mae: 10.2375\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.1960 - mae: 25.1960\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0177 - mae: 17.0177\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.9747 - mae: 25.9747\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.0366 - mae: 18.0366\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3513 - mae: 7.3513\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8516 - mae: 10.8516\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5119 - mae: 19.5119\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.3378 - mae: 10.3378\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6840 - mae: 17.6840\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8826 - mae: 15.8826\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.1778 - mae: 14.1778\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7814 - mae: 8.7814\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0673 - mae: 11.0673\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6998 - mae: 12.6998\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.2395 - mae: 26.2395\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.7524 - mae: 11.7524\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 22.9252 - mae: 22.9252\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2439 - mae: 9.2439\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.3121 - mae: 29.3121\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 53.1141 - mae: 53.1141\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3708 - mae: 12.3708\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.1831 - mae: 12.1831\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9483 - mae: 23.9483\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6223 - mae: 12.6223\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 21.5243 - mae: 21.5243\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3913 - mae: 11.3913\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.4744 - mae: 13.4744\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7992 - mae: 10.7992\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6026 - mae: 16.6026\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9797 - mae: 10.9797\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3049 - mae: 9.3049\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.5985 - mae: 9.5985\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.9750 - mae: 27.9750\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2865 - mae: 11.2865\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.0574 - mae: 14.0574\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.5113 - mae: 13.5113\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.3531 - mae: 17.3531\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5141 - mae: 9.5141\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6965 - mae: 13.6965\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5602 - mae: 11.5602\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.1688 - mae: 30.1688\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7142 - mae: 13.7142\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 26.3987 - mae: 26.3987\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9838 - mae: 25.9838\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2307 - mae: 11.2307\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.2025 - mae: 13.2025\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8624 - mae: 9.8624\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3870 - mae: 13.3870\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9240 - mae: 10.9240\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.5375 - mae: 13.5375\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.6004 - mae: 17.6004\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.1937 - mae: 9.1937\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.4644 - mae: 18.4644\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.1481 - mae: 10.1481\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 24.3358 - mae: 24.3358\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9262 - mae: 10.9262\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8005 - mae: 10.8005\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.3093 - mae: 23.3093\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8134 - mae: 8.8134\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.9715 - mae: 15.9715\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1469 - mae: 8.1469\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4683 - mae: 9.4683\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.1492 - mae: 28.1492\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2183 - mae: 10.2183\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.1686 - mae: 13.1686\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4013 - mae: 18.4013\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0304 - mae: 9.0304\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.4407 - mae: 23.4407\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.1121 - mae: 26.1121\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4009 - mae: 11.4009\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.5022 - mae: 12.5022\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.1948 - mae: 17.1948\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.6097 - mae: 6.6097\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2735 - mae: 20.2735\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1761 - mae: 10.1761\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.3047 - mae: 24.3047\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.9693 - mae: 18.9693\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1749 - mae: 7.1749\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.2784 - mae: 18.2784\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3343 - mae: 13.3343\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7404 - mae: 8.7404\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1947 - mae: 14.1947\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 17.1954 - mae: 17.1954\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.7777 - mae: 16.7777\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1365 - mae: 11.1365\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1982 - mae: 21.1982\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4874 - mae: 10.4874\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5632 - mae: 14.5632\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7188 - mae: 17.7188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5eabdd850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaOHcTHOk4-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "b8ef226a-1a23-4a17-efb2-058e90d41764"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc5eab6fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO5qOmOImtRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9039107-b26c-442e-dc21-1fb0175b0c14"
      },
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_2 = mae(y_test, y_preds_2.squeeze()).numpy()\n",
        "mse_2 = mse(y_test, y_preds_2.squeeze()).numpy()\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.9098114, 5.459232)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9e0DvP6nPr7"
      },
      "source": [
        "#Model 3 - the only difference here is that we are increasing the epochs to 500 and keeping the model 2 same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-zzbTpmnbdW"
      },
      "source": [
        "#** This gives our model more chance to learn pattern from our data **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg593_honjC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1627b2-cd15-42a6-a211-0af89a7dbeef"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_2\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model (this time for 500 epochs, not 100)\n",
        "model_3.fit(X_train, y_train, epochs=500, verbose=0) # set verbose to 0 for less output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5eadeaad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Mb05yln02R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "19370b34-890e-4441-c9d2-1c1e0d37edfc"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Make and plot predictions for model_3\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SWhJJpRn3H0"
      },
      "source": [
        "#Training for too long has given us worse results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDkd1bYjn-GN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4012a9ed-8d71-4e84-c0b4-5ca846f935e7"
      },
      "source": [
        "# Calculate model_3 metrics\n",
        "mae_3 = mae(y_test, y_preds_3.squeeze()).numpy()\n",
        "mse_3 = mse(y_test, y_preds_3.squeeze()).numpy()\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68.68786, 4804.4717)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRKrQ5YQn_7S"
      },
      "source": [
        "#comparing results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ECpde-oDn3"
      },
      "source": [
        "model_results = [[\"model_1\", mae_1, mse_1],\n",
        "                      [\"model_2\",mae_2,mse_2],\n",
        "                     [\"model_3\", mae_3, mse_3]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF2FiAz0oXwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "7b7758e1-ce19-4094-f570-97d6fa3e9fec"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\",\"mse\"])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>1.909811</td>\n",
              "      <td>5.459232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.687859</td>\n",
              "      <td>4804.471680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   1.909811     5.459232\n",
              "2  model_3  68.687859  4804.471680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isodpKo3qr34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28549e0-cc1a-4691-e638-29d60980a6a5"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU7IjrHhq55R"
      },
      "source": [
        "Tracking your experiments\n",
        "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
        "\n",
        "We've done a simple version of this above (keeping the results in different variables).\n",
        "\n",
        " Resource: But as you build more models, you'll want to look into using tools such as:\n",
        "\n",
        "TensorBoard - a component of the TensorFlow library to help track modelling experiments (we'll see this later).\n",
        "Weights & Biases - a tool for tracking all kinds of machine learning experiments (the good news for Weights & Biases is it plugs into TensorBoard).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvs8bBUk3WzI"
      },
      "source": [
        "#Save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5eBpZR3bRS"
      },
      "source": [
        "#Two major formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RyW9aOc3gXd"
      },
      "source": [
        "* The savedModel format\n",
        "* HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh6jy79g3oHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5ff149-5d51-4a8c-e88b-315969c55740"
      },
      "source": [
        "#Option 1\n",
        "model_2.save('best_model_SavedModel_format')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmRK9RRX3x20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934f1bd1-9038-463b-a151-ed6c8e2088a7"
      },
      "source": [
        "#Check it out - outputs a protobuf binary file (.pb) as well as other files\n",
        "!ls best_model_SavedModel_format/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwxd72rN3-bg"
      },
      "source": [
        "#Option 2\n",
        "model_2.save(\"best_model_HDF5_format.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ZLzZ3d4Jbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc082c46-81fb-4faf-f944-895e6e6d9ac7"
      },
      "source": [
        "!ls best_model_HDF5_format.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model_HDF5_format.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITll7Pgp4L6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1359da2e-92ee-4aab-951b-0644970a9d05"
      },
      "source": [
        "#Load the model from saved one\n",
        "loaded_saved_model = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
        "loaded_saved_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxfYuINL4dU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e29ebb5-9bf3-4732-f4da-f7b2ae84052c"
      },
      "source": [
        "#Compare model_2 with the SavedModel version (should return True)\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "saved_model_preds = loaded_saved_model.predict(X_test)\n",
        "mae(y_test, saved_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLQoygAH4mGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967e14aa-9cdf-42f9-f592-2b1706c4d618"
      },
      "source": [
        "# Load a model from the HDF5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdH27H3c971G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb113fad-2b9b-46bf-91b6-72d083d9ccf9"
      },
      "source": [
        "# Compare model_2 with the loaded HDF5 version (should return True)\n",
        "h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "mae(y_test, h5_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG-7hThT9-1w"
      },
      "source": [
        "# A larger example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFb09poa_t0N"
      },
      "source": [
        "#Medical cost dataset\n",
        "\n",
        "#Import required libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7_ctbaCkpE"
      },
      "source": [
        "#Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LofZOwwCqdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "935402cd-af93-476e-a887-d2adda906963"
      },
      "source": [
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16brSOF6CrQV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "16abadea-2081-4236-8d7c-27d411ffd547"
      },
      "source": [
        "#lets try one hot encoding our Datafram so its all numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKl01Vzk83Ka"
      },
      "source": [
        "#Creat X and y values (features and values)\n",
        "X = insurance_one_hot.drop(\"charges\",axis=1)\n",
        "y = insurance_one_hot[\"charges\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uiUkOXXOd6LK",
        "outputId": "6aedca1b-81d4-47cb-ebdd-c4e451e3d6a4"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GUJfjPPd89k",
        "outputId": "9aee9ac6-4bb3-476e-f789-b114997b2150"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XStuQ8ObQC9_",
        "outputId": "67e6a43c-3589-4cbc-b5f3-9a1e292194e1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "len(X), len(X_train), len(X_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfNoFVEebyya",
        "outputId": "40deb6e6-f183-486f-cd3e-e24436fc7174"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new model (same as model_2)\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8868.5918 - mae: 8868.5918\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7887.1606 - mae: 7887.1606\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.0947 - mae: 7537.0947\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 943us/step - loss: 7859.4346 - mae: 7859.4346\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.6699 - mae: 7639.6699\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.0850 - mae: 7578.0850\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7514.6177 - mae: 7514.6177\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7694.1338 - mae: 7694.1338\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.9136 - mae: 7595.9136\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 963us/step - loss: 7735.9116 - mae: 7735.9116\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7444.4189 - mae: 7444.4189\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7678.0337 - mae: 7678.0337\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7681.5840 - mae: 7681.5840\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7702.2842 - mae: 7702.2842\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7585.8921 - mae: 7585.8921\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.5356 - mae: 7689.5356\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7509.2036 - mae: 7509.2036\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7695.0083 - mae: 7695.0083\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 993us/step - loss: 7669.3740 - mae: 7669.3740\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7901.1362 - mae: 7901.1362\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7552.4814 - mae: 7552.4814\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7844.9961 - mae: 7844.9961\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7642.2485 - mae: 7642.2485\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7515.3081 - mae: 7515.3081\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7678.3506 - mae: 7678.3506\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7653.0269 - mae: 7653.0269\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7559.5449 - mae: 7559.5449\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7459.9404 - mae: 7459.9404\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7618.6177 - mae: 7618.6177\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7628.6255 - mae: 7628.6255\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7540.4893 - mae: 7540.4893\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7486.0186 - mae: 7486.0186\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7418.6646 - mae: 7418.6646\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7480.7319 - mae: 7480.7319\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7615.3115 - mae: 7615.3115\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7566.7896 - mae: 7566.7896\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7661.0879 - mae: 7661.0879\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7522.6816 - mae: 7522.6816\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7556.0718 - mae: 7556.0718\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7433.5669 - mae: 7433.5669\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7722.4312 - mae: 7722.4312\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7344.2700 - mae: 7344.2700\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7597.4331 - mae: 7597.4331\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7338.0132 - mae: 7338.0132\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7510.3467 - mae: 7510.3467\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7413.5801 - mae: 7413.5801\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7451.0391 - mae: 7451.0391\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7340.5381 - mae: 7340.5381\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7481.9976 - mae: 7481.9976\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7468.2842 - mae: 7468.2842\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7411.3408 - mae: 7411.3408\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7460.0796 - mae: 7460.0796\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7601.6606 - mae: 7601.6606\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7241.2549 - mae: 7241.2549\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.6953 - mae: 7539.6953\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7293.2012 - mae: 7293.2012\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7417.9731 - mae: 7417.9731\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7353.0625 - mae: 7353.0625\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7643.8247 - mae: 7643.8247\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7410.4004 - mae: 7410.4004\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7612.8330 - mae: 7612.8330\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7387.9087 - mae: 7387.9087\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7359.5605 - mae: 7359.5605\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7109.0884 - mae: 7109.0884\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7396.3223 - mae: 7396.3223\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7179.8613 - mae: 7179.8613\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7289.7710 - mae: 7289.7710\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.6973 - mae: 7523.6973\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.6157 - mae: 7442.6157\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7673.4834 - mae: 7673.4834\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7276.0337 - mae: 7276.0337\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7246.3721 - mae: 7246.3721\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7372.0713 - mae: 7372.0713\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7512.0762 - mae: 7512.0762\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7269.7437 - mae: 7269.7437\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7199.5039 - mae: 7199.5039\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.2920 - mae: 7261.2920\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7185.7627 - mae: 7185.7627\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7301.7495 - mae: 7301.7495\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7002.6309 - mae: 7002.6309\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7289.1357 - mae: 7289.1357\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7155.3945 - mae: 7155.3945\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7475.1709 - mae: 7475.1709\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7387.3672 - mae: 7387.3672\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7289.9458 - mae: 7289.9458\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 997us/step - loss: 7268.0942 - mae: 7268.0942\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7238.5869 - mae: 7238.5869\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7201.7354 - mae: 7201.7349\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7538.0757 - mae: 7538.0757\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6967.1187 - mae: 6967.1187\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7314.1299 - mae: 7314.1299\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7192.3115 - mae: 7192.3115\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7530.8770 - mae: 7530.8770\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 986us/step - loss: 7187.3579 - mae: 7187.3579\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.5635 - mae: 7561.5635\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7263.4648 - mae: 7263.4648\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7146.2896 - mae: 7146.2896\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7247.9238 - mae: 7247.9238\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7200.6694 - mae: 7200.6694\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7301.6870 - mae: 7301.6870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc635aa0490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QY-JUa5dDb4",
        "outputId": "188e0f2d-a7b7-436f-dc91-3e5eddf47ff5"
      },
      "source": [
        "#Evaluate the model which means check the results of the model on test data\n",
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 8628.2393 - mae: 8628.2393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8628.2392578125, 8628.2392578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsSepnxIfm4r",
        "outputId": "0a4cb09a-bf6e-4792-b148-5d41ce6d6115"
      },
      "source": [
        "y_train.median(), y_train.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364489)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F4lFxhxiQcX"
      },
      "source": [
        "#Improving our model as it is not performing well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMLhG1Unicu3"
      },
      "source": [
        "#Adding an extra layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmB_fuzAif-l",
        "outputId": "df101c74-f3f5-4db0-daf6-c888d4261ae2"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new model (same as model_2)\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs=200, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7510 - mae: 12055.7510\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.8408 - mae: 7528.8408\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7024.3501 - mae: 7024.3501\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6652.4614 - mae: 6652.4614\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1006 - mae: 6618.1006\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0444 - mae: 6530.0444\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6506.8071 - mae: 6506.8071\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6310.1948 - mae: 6310.1948\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4987.6191 - mae: 4987.6191\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4915.2910 - mae: 4915.2910\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4847.3599 - mae: 4847.3599\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4768.0151 - mae: 4768.0151\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4683.4727 - mae: 4683.4727\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4600.5054 - mae: 4600.5054\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4513.1436 - mae: 4513.1436\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4422.2983 - mae: 4422.2983\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4339.9600 - mae: 4339.9600\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4254.3916 - mae: 4254.3916\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4173.1797 - mae: 4173.1797\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4102.2939 - mae: 4102.2939\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4031.9592 - mae: 4031.9592\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3986.0220 - mae: 3986.0220\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3943.2346 - mae: 3943.2346\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3918.8977 - mae: 3918.8977\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3895.5610 - mae: 3895.5610\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3869.5679 - mae: 3869.5679\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3850.2136 - mae: 3850.2136\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3834.7349 - mae: 3834.7349\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.0952 - mae: 3827.0952\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3821.6382 - mae: 3821.6382\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3813.8315 - mae: 3813.8315\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3805.7307 - mae: 3805.7307\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.7090 - mae: 3794.7090\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3804.4946 - mae: 3804.4946\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3796.0596 - mae: 3796.0596\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3791.0422 - mae: 3791.0422\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3800.0696 - mae: 3800.0696\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3788.5005 - mae: 3788.5005\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3780.8442 - mae: 3780.8442\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3771.0156 - mae: 3771.0156\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.3762 - mae: 3769.3762\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.7610 - mae: 3766.7610\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.5508 - mae: 3765.5508\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5032 - mae: 3774.5032\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3785.3909 - mae: 3785.3909\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3761.1299 - mae: 3761.1299\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3764.1753 - mae: 3764.1753\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.9250 - mae: 3763.9250\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3762.7959 - mae: 3762.7959\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3754.4397 - mae: 3754.4397\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3347 - mae: 3750.3347\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.4006 - mae: 3750.4006\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3755.4736 - mae: 3755.4736\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3223 - mae: 3750.3223\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3758.1089 - mae: 3758.1089\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4858 - mae: 3743.4858\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3738.5342 - mae: 3738.5342\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3740.1384 - mae: 3740.1384\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3742.4954 - mae: 3742.4954\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.4399 - mae: 3744.4399\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1824 - mae: 3737.1824\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.6541 - mae: 3737.6541\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1663 - mae: 3737.1663\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3733.1101 - mae: 3733.1101\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3729.5813 - mae: 3729.5813\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.9053 - mae: 3725.9053\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3733.2817 - mae: 3733.2817\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3728.2559 - mae: 3728.2559\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.5825 - mae: 3724.5825\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3723.0806 - mae: 3723.0806\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.9475 - mae: 3726.9475\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3716.5430 - mae: 3716.5430\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.9155 - mae: 3721.9155\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.1814 - mae: 3721.1814\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.2456 - mae: 3715.2456\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.9756 - mae: 3713.9756\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.9922 - mae: 3707.9922\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.4158 - mae: 3707.4158\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.6833 - mae: 3710.6833\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3703.3618 - mae: 3703.3618\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.9385 - mae: 3710.9385\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.0417 - mae: 3713.0417\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.0571 - mae: 3705.0571\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3698.9333 - mae: 3698.9333\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.9983 - mae: 3697.9983\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3704.9150 - mae: 3704.9150\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.3679 - mae: 3710.3679\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.6482 - mae: 3696.6482\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3692.7329 - mae: 3692.7329\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.1655 - mae: 3691.1655\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3699.2437 - mae: 3699.2437\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.2480 - mae: 3693.2480\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3696.1387 - mae: 3696.1387\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.8640 - mae: 3687.8640\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.3562 - mae: 3693.3562\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.7324 - mae: 3682.7324\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3683.2891 - mae: 3683.2891\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.6536 - mae: 3697.6536\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3684.6665 - mae: 3684.6665\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.5154 - mae: 3675.5154\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3923 - mae: 3676.3923\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.8452 - mae: 3672.8452\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.0283 - mae: 3682.0283\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.7961 - mae: 3665.7961\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3671.7419 - mae: 3671.7419\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.5464 - mae: 3680.5464\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.6401 - mae: 3665.6401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc635915d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Je28I1xjAol",
        "outputId": "de36f063-141d-42f8-cda2-eb038317d264"
      },
      "source": [
        "insurance_model_2.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8kF3x2ojEcQ",
        "outputId": "60929a0c-2b0a-4fd7-bd6e-2ec114b43047"
      },
      "source": [
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 8628.2393 - mae: 8628.2393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8628.2392578125, 8628.2392578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlGiprjIj7a0",
        "outputId": "3b84fb71-6742-40e6-a8d1-0a7044a553b8"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new model (same as model_2)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12055.7510 - mae: 12055.7510\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7528.8408 - mae: 7528.8408\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7024.3501 - mae: 7024.3501\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6652.4614 - mae: 6652.4614\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1006 - mae: 6618.1006\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6530.0444 - mae: 6530.0444\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6218.0430 - mae: 6218.0430\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4987.6191 - mae: 4987.6191\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4915.2910 - mae: 4915.2910\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4847.3599 - mae: 4847.3599\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4768.0151 - mae: 4768.0151\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4683.4727 - mae: 4683.4727\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4600.5054 - mae: 4600.5054\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4513.1436 - mae: 4513.1436\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4422.2983 - mae: 4422.2983\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4339.9600 - mae: 4339.9600\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4254.3916 - mae: 4254.3916\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4173.1797 - mae: 4173.1797\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4102.2939 - mae: 4102.2939\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4031.9592 - mae: 4031.9592\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3986.0220 - mae: 3986.0220\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3943.2346 - mae: 3943.2346\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3918.8977 - mae: 3918.8977\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3895.5610 - mae: 3895.5610\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3869.5679 - mae: 3869.5679\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3850.2136 - mae: 3850.2136\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3834.7349 - mae: 3834.7349\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.0952 - mae: 3827.0952\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3821.6382 - mae: 3821.6382\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3813.8315 - mae: 3813.8315\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3805.7307 - mae: 3805.7307\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.7090 - mae: 3794.7090\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3804.4946 - mae: 3804.4946\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3796.0596 - mae: 3796.0596\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3791.0422 - mae: 3791.0422\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3800.0696 - mae: 3800.0696\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3788.5005 - mae: 3788.5005\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3780.8442 - mae: 3780.8442\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.0156 - mae: 3771.0156\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.3762 - mae: 3769.3762\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.7610 - mae: 3766.7610\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3765.5508 - mae: 3765.5508\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5032 - mae: 3774.5032\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3785.3909 - mae: 3785.3909\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3761.1299 - mae: 3761.1299\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.1753 - mae: 3764.1753\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.9250 - mae: 3763.9250\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3762.7959 - mae: 3762.7959\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3754.4397 - mae: 3754.4397\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3347 - mae: 3750.3347\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.4006 - mae: 3750.4006\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3755.4736 - mae: 3755.4736\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3223 - mae: 3750.3223\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.1089 - mae: 3758.1089\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4858 - mae: 3743.4858\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3738.5342 - mae: 3738.5342\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3740.1384 - mae: 3740.1384\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3742.4954 - mae: 3742.4954\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.4399 - mae: 3744.4399\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1824 - mae: 3737.1824\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.6541 - mae: 3737.6541\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1663 - mae: 3737.1663\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.1101 - mae: 3733.1101\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.5813 - mae: 3729.5813\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.9053 - mae: 3725.9053\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.2817 - mae: 3733.2817\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3728.2559 - mae: 3728.2559\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.5825 - mae: 3724.5825\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3723.0806 - mae: 3723.0806\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.9475 - mae: 3726.9475\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.5430 - mae: 3716.5430\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3721.9155 - mae: 3721.9155\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.1814 - mae: 3721.1814\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.2456 - mae: 3715.2456\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.9756 - mae: 3713.9756\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.9922 - mae: 3707.9922\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3707.4158 - mae: 3707.4158\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.6833 - mae: 3710.6833\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3703.3618 - mae: 3703.3618\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3710.9385 - mae: 3710.9385\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.0417 - mae: 3713.0417\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.0571 - mae: 3705.0571\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3698.9333 - mae: 3698.9333\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.9983 - mae: 3697.9983\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3704.9150 - mae: 3704.9150\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.3679 - mae: 3710.3679\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.6482 - mae: 3696.6482\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3692.7329 - mae: 3692.7329\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.1655 - mae: 3691.1655\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3699.2437 - mae: 3699.2437\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.2480 - mae: 3693.2480\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.1387 - mae: 3696.1387\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.8640 - mae: 3687.8640\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.3562 - mae: 3693.3562\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.7324 - mae: 3682.7324\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3683.2891 - mae: 3683.2891\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.6536 - mae: 3697.6536\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3684.6665 - mae: 3684.6665\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.5154 - mae: 3675.5154\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3923 - mae: 3676.3923\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.8452 - mae: 3672.8452\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.0283 - mae: 3682.0283\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3665.7961 - mae: 3665.7961\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3671.7419 - mae: 3671.7419\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.5464 - mae: 3680.5464\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.6401 - mae: 3665.6401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rYomlz-lZg2",
        "outputId": "6054e310-6ae4-4791-9d46-98f8b7df918a"
      },
      "source": [
        "#Evaluate with increasing the epochs to 200\n",
        "\n",
        "insurance_model_3.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "TP7zwCW8lvG6",
        "outputId": "fedcf101-076c-4fcf-acb7-e3ddb6a742aa"
      },
      "source": [
        "#Plot history which also means loss curve or training curve\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD_ArsJnoQVp"
      },
      "source": [
        "#Preprocessing data (normalization and standardization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1kTXkyArGbF"
      },
      "source": [
        "#Neural networks tend to prefer normalization over standardization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ct3gCPngywsb",
        "outputId": "82a508aa-442d-406e-ae64-60855ee0a04f"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "#Read in the insurance dataframe\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grb7RcA8zBEf"
      },
      "source": [
        "#To prepare our data we can borrow a few classes from scikit learn\n",
        "``The major difference between normalization and one hot encoding is that normalization turns all the numerical values of the columns into 0 and 1 and one hot encoding does the same for only string values``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTuQ4aMwzIzx"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Create column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(),[\"age\",\"bmi\", \"children\"]), #turn all values in this column into 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\", \"region\"]) # ignores the columns which it does not know about\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "#Build our train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "#Fit the column transformer on our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "#Transforming training and test data with normalization (MinMaxScalar) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ3If0ja4e8u",
        "outputId": "682179e2-1859-4861-a02e-ecac4b35e198"
      },
      "source": [
        "# How does the old data look now\n",
        "X_train.loc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ge2TvIb43yc",
        "outputId": "0184b601-a3e1-4a69-e65d-eedb24cf521f"
      },
      "source": [
        "#normalized data\n",
        "X_train_normal[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciY9739I5Nla",
        "outputId": "3dd1853b-c135-4de0-cb54-d76a24f164c1"
      },
      "source": [
        "# The normalized data shape is larger than old because of the extra columns\n",
        "X_train_normal.shape, X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (1070, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La2KLTSq6ZAV",
        "outputId": "4b633db6-4fa8-4f58-b170-c69cb010aa28"
      },
      "source": [
        "#Lets use our model number 2\n",
        "\n",
        "#set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "\n",
        "#Fit the model\n",
        "insurance_model_3.fit(X_train_normal, y_train, epochs=500)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13340.4238 - mae: 13340.4238\n",
            "Epoch 2/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13304.7178 - mae: 13304.7178\n",
            "Epoch 3/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13178.4893 - mae: 13178.4893\n",
            "Epoch 4/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12868.2793 - mae: 12868.2793\n",
            "Epoch 5/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12269.2344 - mae: 12269.2344\n",
            "Epoch 6/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11321.8975 - mae: 11321.8975\n",
            "Epoch 7/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10218.4619 - mae: 10218.4619\n",
            "Epoch 8/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9182.0342 - mae: 9182.0342\n",
            "Epoch 9/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8458.1797 - mae: 8458.1797\n",
            "Epoch 10/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8055.3774 - mae: 8055.3774\n",
            "Epoch 11/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7886.5391 - mae: 7886.5391\n",
            "Epoch 12/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7778.5771 - mae: 7778.5771\n",
            "Epoch 13/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7690.8481 - mae: 7690.8481\n",
            "Epoch 14/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7596.6533 - mae: 7596.6533\n",
            "Epoch 15/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7504.1958 - mae: 7504.1958\n",
            "Epoch 16/500\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7408.9077 - mae: 7408.9077\n",
            "Epoch 17/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7306.5928 - mae: 7306.5928\n",
            "Epoch 18/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7200.9854 - mae: 7200.9854\n",
            "Epoch 19/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7088.3433 - mae: 7088.3433\n",
            "Epoch 20/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6967.4761 - mae: 6967.4761\n",
            "Epoch 21/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6840.0283 - mae: 6840.0283\n",
            "Epoch 22/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6697.2129 - mae: 6697.2129\n",
            "Epoch 23/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6540.8154 - mae: 6540.8154\n",
            "Epoch 24/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6373.2793 - mae: 6373.2793\n",
            "Epoch 25/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6199.5293 - mae: 6199.5293\n",
            "Epoch 26/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5974.2285 - mae: 5974.2285\n",
            "Epoch 27/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5747.9106 - mae: 5747.9106\n",
            "Epoch 28/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5503.9219 - mae: 5503.9219\n",
            "Epoch 29/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5242.3237 - mae: 5242.3237\n",
            "Epoch 30/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4968.8145 - mae: 4968.8145\n",
            "Epoch 31/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4688.7427 - mae: 4688.7427\n",
            "Epoch 32/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4430.6016 - mae: 4430.6016\n",
            "Epoch 33/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4216.4829 - mae: 4216.4829\n",
            "Epoch 34/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4021.4539 - mae: 4021.4539\n",
            "Epoch 35/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3870.4365 - mae: 3870.4365\n",
            "Epoch 36/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.9243 - mae: 3764.9243\n",
            "Epoch 37/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.5715 - mae: 3710.5715\n",
            "Epoch 38/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.7473 - mae: 3687.7473\n",
            "Epoch 39/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3670.6694 - mae: 3670.6694\n",
            "Epoch 40/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.3552 - mae: 3665.3552\n",
            "Epoch 41/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.5032 - mae: 3655.5032\n",
            "Epoch 42/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3663.7034 - mae: 3663.7034\n",
            "Epoch 43/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.8245 - mae: 3655.8245\n",
            "Epoch 44/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3647.2397 - mae: 3647.2397\n",
            "Epoch 45/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3642.5217 - mae: 3642.5217\n",
            "Epoch 46/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3641.3706 - mae: 3641.3706\n",
            "Epoch 47/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3639.2358 - mae: 3639.2358\n",
            "Epoch 48/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3632.9512 - mae: 3632.9512\n",
            "Epoch 49/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3631.5464 - mae: 3631.5464\n",
            "Epoch 50/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3625.5815 - mae: 3625.5815\n",
            "Epoch 51/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3629.8359 - mae: 3629.8359\n",
            "Epoch 52/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.0671 - mae: 3624.0671\n",
            "Epoch 53/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3616.5146 - mae: 3616.5146\n",
            "Epoch 54/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3616.8682 - mae: 3616.8682\n",
            "Epoch 55/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3616.2100 - mae: 3616.2100\n",
            "Epoch 56/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3603.4614 - mae: 3603.4614\n",
            "Epoch 57/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3600.4526 - mae: 3600.4526\n",
            "Epoch 58/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3595.7332 - mae: 3595.7332\n",
            "Epoch 59/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.5254 - mae: 3594.5254\n",
            "Epoch 60/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3587.7358 - mae: 3587.7358\n",
            "Epoch 61/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3585.5505 - mae: 3585.5505\n",
            "Epoch 62/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.7683 - mae: 3578.7683\n",
            "Epoch 63/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3574.3367 - mae: 3574.3367\n",
            "Epoch 64/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3572.4990 - mae: 3572.4990\n",
            "Epoch 65/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3573.0952 - mae: 3573.0952\n",
            "Epoch 66/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.1401 - mae: 3563.1401\n",
            "Epoch 67/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.5928 - mae: 3561.5928\n",
            "Epoch 68/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.0784 - mae: 3561.0784\n",
            "Epoch 69/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.3484 - mae: 3554.3484\n",
            "Epoch 70/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3553.6023 - mae: 3553.6023\n",
            "Epoch 71/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.5007 - mae: 3552.5007\n",
            "Epoch 72/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.0906 - mae: 3544.0906\n",
            "Epoch 73/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.1575 - mae: 3542.1575\n",
            "Epoch 74/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.2681 - mae: 3536.2681\n",
            "Epoch 75/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.7825 - mae: 3535.7825\n",
            "Epoch 76/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.2686 - mae: 3536.2686\n",
            "Epoch 77/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.5537 - mae: 3525.5537\n",
            "Epoch 78/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.0613 - mae: 3523.0613\n",
            "Epoch 79/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.9214 - mae: 3525.9214\n",
            "Epoch 80/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.8506 - mae: 3520.8506\n",
            "Epoch 81/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.1433 - mae: 3518.1433\n",
            "Epoch 82/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.9719 - mae: 3515.9719\n",
            "Epoch 83/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.1436 - mae: 3513.1436\n",
            "Epoch 84/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.8445 - mae: 3508.8445\n",
            "Epoch 85/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.5527 - mae: 3505.5527\n",
            "Epoch 86/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.7927 - mae: 3501.7927\n",
            "Epoch 87/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.6873 - mae: 3501.6873\n",
            "Epoch 88/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3497.7844 - mae: 3497.7844\n",
            "Epoch 89/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3497.2859 - mae: 3497.2859\n",
            "Epoch 90/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3492.3335 - mae: 3492.3335\n",
            "Epoch 91/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.6113 - mae: 3485.6113\n",
            "Epoch 92/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3487.3831 - mae: 3487.3831\n",
            "Epoch 93/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.7871 - mae: 3481.7871\n",
            "Epoch 94/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.0571 - mae: 3479.0571\n",
            "Epoch 95/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6052 - mae: 3478.6052\n",
            "Epoch 96/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.4221 - mae: 3482.4221\n",
            "Epoch 97/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.4578 - mae: 3480.4578\n",
            "Epoch 98/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1211 - mae: 3475.1211\n",
            "Epoch 99/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8147 - mae: 3475.8147\n",
            "Epoch 100/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.1475 - mae: 3480.1475\n",
            "Epoch 101/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3896 - mae: 3476.3896\n",
            "Epoch 102/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8818 - mae: 3475.8818\n",
            "Epoch 103/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8379 - mae: 3474.8379\n",
            "Epoch 104/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1633 - mae: 3474.1633\n",
            "Epoch 105/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4209 - mae: 3477.4209\n",
            "Epoch 106/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8533 - mae: 3474.8533\n",
            "Epoch 107/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.2874 - mae: 3478.2874\n",
            "Epoch 108/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1938 - mae: 3476.1938\n",
            "Epoch 109/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6506 - mae: 3478.6506\n",
            "Epoch 110/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9653 - mae: 3472.9653\n",
            "Epoch 111/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.2512 - mae: 3484.2512\n",
            "Epoch 112/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.0217 - mae: 3478.0217\n",
            "Epoch 113/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.6731 - mae: 3479.6731\n",
            "Epoch 114/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.4006 - mae: 3481.4006\n",
            "Epoch 115/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5281 - mae: 3475.5281\n",
            "Epoch 116/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4897 - mae: 3477.4897\n",
            "Epoch 117/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.6091 - mae: 3479.6091\n",
            "Epoch 118/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2991 - mae: 3474.2991\n",
            "Epoch 119/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.8711 - mae: 3479.8711\n",
            "Epoch 120/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4919 - mae: 3473.4919\n",
            "Epoch 121/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4553 - mae: 3477.4553\n",
            "Epoch 122/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5918 - mae: 3475.5918\n",
            "Epoch 123/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.2075 - mae: 3475.2075\n",
            "Epoch 124/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8289 - mae: 3473.8289\n",
            "Epoch 125/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4866 - mae: 3475.4866\n",
            "Epoch 126/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1313 - mae: 3474.1313\n",
            "Epoch 127/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.6255 - mae: 3477.6255\n",
            "Epoch 128/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.0808 - mae: 3478.0808\n",
            "Epoch 129/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.2170 - mae: 3478.2170\n",
            "Epoch 130/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6941 - mae: 3474.6941\n",
            "Epoch 131/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7712 - mae: 3475.7712\n",
            "Epoch 132/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5105 - mae: 3474.5105\n",
            "Epoch 133/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7793 - mae: 3473.7793\n",
            "Epoch 134/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7153 - mae: 3474.7153\n",
            "Epoch 135/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0864 - mae: 3475.0864\n",
            "Epoch 136/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9075 - mae: 3472.9075\n",
            "Epoch 137/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8379 - mae: 3475.8379\n",
            "Epoch 138/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5488 - mae: 3475.5488\n",
            "Epoch 139/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8591 - mae: 3475.8591\n",
            "Epoch 140/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0188 - mae: 3474.0188\n",
            "Epoch 141/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.7568 - mae: 3479.7568\n",
            "Epoch 142/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6379 - mae: 3478.6379\n",
            "Epoch 143/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4304 - mae: 3474.4304\n",
            "Epoch 144/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.6729 - mae: 3477.6729\n",
            "Epoch 145/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4709 - mae: 3475.4709\n",
            "Epoch 146/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.8616 - mae: 3479.8616\n",
            "Epoch 147/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9229 - mae: 3474.9229\n",
            "Epoch 148/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4265 - mae: 3478.4265\n",
            "Epoch 149/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6191 - mae: 3473.6191\n",
            "Epoch 150/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9265 - mae: 3475.9265\n",
            "Epoch 151/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.5068 - mae: 3476.5068\n",
            "Epoch 152/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.2434 - mae: 3478.2434\n",
            "Epoch 153/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6807 - mae: 3473.6807\n",
            "Epoch 154/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8167 - mae: 3475.8167\n",
            "Epoch 155/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1484 - mae: 3475.1484\n",
            "Epoch 156/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.3975 - mae: 3479.3975\n",
            "Epoch 157/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.8059 - mae: 3478.8059\n",
            "Epoch 158/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4668 - mae: 3474.4668\n",
            "Epoch 159/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.2473 - mae: 3473.2473\n",
            "Epoch 160/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.6775 - mae: 3476.6775\n",
            "Epoch 161/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4907 - mae: 3475.4907\n",
            "Epoch 162/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.9998 - mae: 3473.9998\n",
            "Epoch 163/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1721 - mae: 3474.1721\n",
            "Epoch 164/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.9563 - mae: 3478.9563\n",
            "Epoch 165/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2029 - mae: 3474.2029\n",
            "Epoch 166/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5818 - mae: 3475.5818\n",
            "Epoch 167/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4460 - mae: 3475.4460\n",
            "Epoch 168/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5320 - mae: 3474.5320\n",
            "Epoch 169/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0696 - mae: 3473.0696\n",
            "Epoch 170/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8059 - mae: 3475.8059\n",
            "Epoch 171/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1411 - mae: 3474.1411\n",
            "Epoch 172/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1426 - mae: 3475.1426\n",
            "Epoch 173/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5415 - mae: 3474.5415\n",
            "Epoch 174/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9314 - mae: 3475.9314\n",
            "Epoch 175/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7271 - mae: 3475.7271\n",
            "Epoch 176/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.0667 - mae: 3480.0667\n",
            "Epoch 177/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.6301 - mae: 3479.6301\n",
            "Epoch 178/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.6936 - mae: 3476.6936\n",
            "Epoch 179/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.1138 - mae: 3483.1138\n",
            "Epoch 180/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.6877 - mae: 3476.6877\n",
            "Epoch 181/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9241 - mae: 3475.9241\n",
            "Epoch 182/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6116 - mae: 3475.6116\n",
            "Epoch 183/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8093 - mae: 3474.8093\n",
            "Epoch 184/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2576 - mae: 3476.2576\n",
            "Epoch 185/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2144 - mae: 3477.2144\n",
            "Epoch 186/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3926 - mae: 3474.3926\n",
            "Epoch 187/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9705 - mae: 3474.9705\n",
            "Epoch 188/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.2910 - mae: 3473.2910\n",
            "Epoch 189/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4333 - mae: 3473.4333\n",
            "Epoch 190/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.9258 - mae: 3476.9258\n",
            "Epoch 191/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3490.0850 - mae: 3490.0850\n",
            "Epoch 192/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.6770 - mae: 3476.6770\n",
            "Epoch 193/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2507 - mae: 3476.2507\n",
            "Epoch 194/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7363 - mae: 3474.7363\n",
            "Epoch 195/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.6807 - mae: 3472.6807\n",
            "Epoch 196/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.4329 - mae: 3480.4329\n",
            "Epoch 197/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8413 - mae: 3474.8413\n",
            "Epoch 198/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.1328 - mae: 3479.1328\n",
            "Epoch 199/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7659 - mae: 3473.7659\n",
            "Epoch 200/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3311 - mae: 3476.3311\n",
            "Epoch 201/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1316 - mae: 3476.1316\n",
            "Epoch 202/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5894 - mae: 3475.5894\n",
            "Epoch 203/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.0229 - mae: 3474.0229\n",
            "Epoch 204/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4360 - mae: 3473.4360\n",
            "Epoch 205/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.2390 - mae: 3475.2390\n",
            "Epoch 206/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.9429 - mae: 3471.9429\n",
            "Epoch 207/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2644 - mae: 3477.2644\n",
            "Epoch 208/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7312 - mae: 3475.7312\n",
            "Epoch 209/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8962 - mae: 3475.8962\n",
            "Epoch 210/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.2576 - mae: 3475.2576\n",
            "Epoch 211/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8516 - mae: 3473.8516\n",
            "Epoch 212/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.5200 - mae: 3476.5200\n",
            "Epoch 213/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4380 - mae: 3474.4380\n",
            "Epoch 214/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.1387 - mae: 3477.1387\n",
            "Epoch 215/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8259 - mae: 3475.8259\n",
            "Epoch 216/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2158 - mae: 3477.2158\n",
            "Epoch 217/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.6611 - mae: 3479.6611\n",
            "Epoch 218/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0120 - mae: 3474.0120\n",
            "Epoch 219/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7341 - mae: 3474.7341\n",
            "Epoch 220/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.3655 - mae: 3473.3655\n",
            "Epoch 221/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4119 - mae: 3477.4119\n",
            "Epoch 222/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.7830 - mae: 3477.7830\n",
            "Epoch 223/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2971 - mae: 3474.2971\n",
            "Epoch 224/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3979 - mae: 3476.3979\n",
            "Epoch 225/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.3679 - mae: 3475.3679\n",
            "Epoch 226/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7532 - mae: 3473.7532\n",
            "Epoch 227/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9927 - mae: 3472.9927\n",
            "Epoch 228/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.8342 - mae: 3476.8342\n",
            "Epoch 229/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9521 - mae: 3472.9521\n",
            "Epoch 230/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.5071 - mae: 3478.5071\n",
            "Epoch 231/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8730 - mae: 3473.8730\n",
            "Epoch 232/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0125 - mae: 3473.0125\n",
            "Epoch 233/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8169 - mae: 3474.8169\n",
            "Epoch 234/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3894 - mae: 3474.3894\n",
            "Epoch 235/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0618 - mae: 3476.0618\n",
            "Epoch 236/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9685 - mae: 3475.9685\n",
            "Epoch 237/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0833 - mae: 3476.0833\n",
            "Epoch 238/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.5710 - mae: 3472.5710\n",
            "Epoch 239/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.7161 - mae: 3478.7161\n",
            "Epoch 240/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.3787 - mae: 3475.3787\n",
            "Epoch 241/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0847 - mae: 3473.0847\n",
            "Epoch 242/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2432 - mae: 3476.2432\n",
            "Epoch 243/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6379 - mae: 3473.6379\n",
            "Epoch 244/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.3093 - mae: 3478.3093\n",
            "Epoch 245/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5598 - mae: 3474.5598\n",
            "Epoch 246/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9043 - mae: 3476.9043\n",
            "Epoch 247/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5806 - mae: 3475.5806\n",
            "Epoch 248/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4006 - mae: 3477.4006\n",
            "Epoch 249/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4661 - mae: 3478.4661\n",
            "Epoch 250/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4407 - mae: 3475.4407\n",
            "Epoch 251/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.8882 - mae: 3472.8882\n",
            "Epoch 252/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4524 - mae: 3476.4524\n",
            "Epoch 253/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9207 - mae: 3476.9207\n",
            "Epoch 254/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8010 - mae: 3474.8010\n",
            "Epoch 255/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1609 - mae: 3474.1609\n",
            "Epoch 256/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.9446 - mae: 3480.9446\n",
            "Epoch 257/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.2012 - mae: 3480.2012\n",
            "Epoch 258/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1357 - mae: 3474.1357\n",
            "Epoch 259/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.7100 - mae: 3478.7100\n",
            "Epoch 260/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3870 - mae: 3474.3870\n",
            "Epoch 261/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1494 - mae: 3476.1494\n",
            "Epoch 262/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7981 - mae: 3474.7981\n",
            "Epoch 263/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.5251 - mae: 3476.5251\n",
            "Epoch 264/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6931 - mae: 3475.6931\n",
            "Epoch 265/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7673 - mae: 3473.7673\n",
            "Epoch 266/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4490 - mae: 3476.4490\n",
            "Epoch 267/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9763 - mae: 3476.9763\n",
            "Epoch 268/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.5454 - mae: 3473.5454\n",
            "Epoch 269/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6094 - mae: 3473.6094\n",
            "Epoch 270/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7747 - mae: 3473.7747\n",
            "Epoch 271/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.1450 - mae: 3474.1450\n",
            "Epoch 272/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0378 - mae: 3474.0378\n",
            "Epoch 273/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6643 - mae: 3474.6643\n",
            "Epoch 274/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.2727 - mae: 3473.2727\n",
            "Epoch 275/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3364 - mae: 3474.3364\n",
            "Epoch 276/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2615 - mae: 3476.2615\n",
            "Epoch 277/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6292 - mae: 3473.6292\n",
            "Epoch 278/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0037 - mae: 3476.0037\n",
            "Epoch 279/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.0642 - mae: 3482.0642\n",
            "Epoch 280/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7043 - mae: 3474.7043\n",
            "Epoch 281/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7598 - mae: 3474.7598\n",
            "Epoch 282/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2219 - mae: 3474.2219\n",
            "Epoch 283/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6099 - mae: 3475.6099\n",
            "Epoch 284/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2463 - mae: 3474.2463\n",
            "Epoch 285/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.9683 - mae: 3473.9683\n",
            "Epoch 286/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9529 - mae: 3474.9529\n",
            "Epoch 287/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0701 - mae: 3475.0701\n",
            "Epoch 288/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5137 - mae: 3474.5137\n",
            "Epoch 289/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.8894 - mae: 3477.8894\n",
            "Epoch 290/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.3289 - mae: 3478.3289\n",
            "Epoch 291/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.3669 - mae: 3472.3669\n",
            "Epoch 292/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.9163 - mae: 3478.9163\n",
            "Epoch 293/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.3455 - mae: 3473.3455\n",
            "Epoch 294/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4788 - mae: 3478.4788\n",
            "Epoch 295/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.1311 - mae: 3478.1311\n",
            "Epoch 296/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.1599 - mae: 3478.1599\n",
            "Epoch 297/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.2959 - mae: 3482.2959\n",
            "Epoch 298/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.9583 - mae: 3481.9583\n",
            "Epoch 299/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9089 - mae: 3474.9089\n",
            "Epoch 300/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.3403 - mae: 3475.3403\n",
            "Epoch 301/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.9880 - mae: 3475.9880\n",
            "Epoch 302/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6335 - mae: 3478.6335\n",
            "Epoch 303/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1169 - mae: 3475.1169\n",
            "Epoch 304/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1963 - mae: 3475.1963\n",
            "Epoch 305/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.7112 - mae: 3476.7112\n",
            "Epoch 306/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9370 - mae: 3476.9370\n",
            "Epoch 307/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.9160 - mae: 3478.9160\n",
            "Epoch 308/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0266 - mae: 3475.0266\n",
            "Epoch 309/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4199 - mae: 3477.4199\n",
            "Epoch 310/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.5945 - mae: 3478.5945\n",
            "Epoch 311/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2732 - mae: 3474.2732\n",
            "Epoch 312/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0278 - mae: 3475.0278\n",
            "Epoch 313/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5459 - mae: 3474.5459\n",
            "Epoch 314/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.3120 - mae: 3473.3120\n",
            "Epoch 315/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8237 - mae: 3474.8237\n",
            "Epoch 316/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.5034 - mae: 3475.5034\n",
            "Epoch 317/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4412 - mae: 3474.4412\n",
            "Epoch 318/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9023 - mae: 3476.9023\n",
            "Epoch 319/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2083 - mae: 3477.2083\n",
            "Epoch 320/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6785 - mae: 3473.6785\n",
            "Epoch 321/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4514 - mae: 3475.4514\n",
            "Epoch 322/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.9617 - mae: 3477.9617\n",
            "Epoch 323/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.9265 - mae: 3473.9265\n",
            "Epoch 324/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6030 - mae: 3474.6030\n",
            "Epoch 325/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4829 - mae: 3475.4829\n",
            "Epoch 326/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7312 - mae: 3473.7312\n",
            "Epoch 327/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.8398 - mae: 3478.8398\n",
            "Epoch 328/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0620 - mae: 3476.0620\n",
            "Epoch 329/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6658 - mae: 3475.6658\n",
            "Epoch 330/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4990 - mae: 3478.4990\n",
            "Epoch 331/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0774 - mae: 3473.0774\n",
            "Epoch 332/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1230 - mae: 3475.1230\n",
            "Epoch 333/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.5129 - mae: 3479.5129\n",
            "Epoch 334/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4480 - mae: 3474.4480\n",
            "Epoch 335/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3313 - mae: 3476.3313\n",
            "Epoch 336/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4758 - mae: 3473.4758\n",
            "Epoch 337/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.0920 - mae: 3472.0920\n",
            "Epoch 338/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7883 - mae: 3475.7883\n",
            "Epoch 339/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4463 - mae: 3474.4463\n",
            "Epoch 340/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6348 - mae: 3478.6348\n",
            "Epoch 341/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1506 - mae: 3476.1506\n",
            "Epoch 342/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9250 - mae: 3475.9250\n",
            "Epoch 343/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.8396 - mae: 3472.8396\n",
            "Epoch 344/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.3289 - mae: 3475.3289\n",
            "Epoch 345/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7065 - mae: 3473.7065\n",
            "Epoch 346/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.4827 - mae: 3478.4827\n",
            "Epoch 347/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0376 - mae: 3474.0376\n",
            "Epoch 348/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1121 - mae: 3475.1121\n",
            "Epoch 349/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4817 - mae: 3475.4817\n",
            "Epoch 350/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.0298 - mae: 3482.0298\n",
            "Epoch 351/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.5208 - mae: 3477.5208\n",
            "Epoch 352/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6335 - mae: 3474.6335\n",
            "Epoch 353/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1401 - mae: 3474.1401\n",
            "Epoch 354/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7991 - mae: 3475.7991\n",
            "Epoch 355/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0129 - mae: 3475.0129\n",
            "Epoch 356/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0259 - mae: 3476.0259\n",
            "Epoch 357/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9573 - mae: 3474.9573\n",
            "Epoch 358/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3487.9749 - mae: 3487.9749\n",
            "Epoch 359/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.9592 - mae: 3477.9592\n",
            "Epoch 360/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.5815 - mae: 3474.5815\n",
            "Epoch 361/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5354 - mae: 3475.5354\n",
            "Epoch 362/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5786 - mae: 3475.5786\n",
            "Epoch 363/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7664 - mae: 3475.7664\n",
            "Epoch 364/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.7739 - mae: 3473.7739\n",
            "Epoch 365/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.4746 - mae: 3474.4746\n",
            "Epoch 366/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.7063 - mae: 3476.7063\n",
            "Epoch 367/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.9463 - mae: 3473.9463\n",
            "Epoch 368/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.7886 - mae: 3479.7886\n",
            "Epoch 369/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2651 - mae: 3477.2651\n",
            "Epoch 370/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.6040 - mae: 3474.6040\n",
            "Epoch 371/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0662 - mae: 3475.0662\n",
            "Epoch 372/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.7905 - mae: 3472.7905\n",
            "Epoch 373/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.0740 - mae: 3480.0740\n",
            "Epoch 374/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6299 - mae: 3478.6299\n",
            "Epoch 375/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6782 - mae: 3475.6782\n",
            "Epoch 376/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1062 - mae: 3476.1062\n",
            "Epoch 377/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8901 - mae: 3474.8901\n",
            "Epoch 378/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7075 - mae: 3474.7075\n",
            "Epoch 379/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.0200 - mae: 3481.0200\n",
            "Epoch 380/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.5754 - mae: 3474.5754\n",
            "Epoch 381/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6316 - mae: 3478.6316\n",
            "Epoch 382/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0857 - mae: 3474.0857\n",
            "Epoch 383/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1548 - mae: 3474.1548\n",
            "Epoch 384/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.9883 - mae: 3475.9883\n",
            "Epoch 385/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.9946 - mae: 3480.9946\n",
            "Epoch 386/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6157 - mae: 3473.6157\n",
            "Epoch 387/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5239 - mae: 3475.5239\n",
            "Epoch 388/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4519 - mae: 3475.4519\n",
            "Epoch 389/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7261 - mae: 3475.7261\n",
            "Epoch 390/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0867 - mae: 3476.0867\n",
            "Epoch 391/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.4983 - mae: 3477.4983\n",
            "Epoch 392/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.8218 - mae: 3481.8218\n",
            "Epoch 393/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.4595 - mae: 3479.4595\n",
            "Epoch 394/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9873 - mae: 3472.9873\n",
            "Epoch 395/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0950 - mae: 3476.0950\n",
            "Epoch 396/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9651 - mae: 3474.9651\n",
            "Epoch 397/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.6494 - mae: 3475.6494\n",
            "Epoch 398/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4312 - mae: 3473.4312\n",
            "Epoch 399/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6816 - mae: 3478.6816\n",
            "Epoch 400/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.6692 - mae: 3476.6692\n",
            "Epoch 401/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.6064 - mae: 3477.6064\n",
            "Epoch 402/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0344 - mae: 3476.0344\n",
            "Epoch 403/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4111 - mae: 3476.4111\n",
            "Epoch 404/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0188 - mae: 3473.0188\n",
            "Epoch 405/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.3979 - mae: 3477.3979\n",
            "Epoch 406/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1714 - mae: 3476.1714\n",
            "Epoch 407/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6304 - mae: 3473.6304\n",
            "Epoch 408/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1250 - mae: 3475.1250\n",
            "Epoch 409/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.0891 - mae: 3476.0891\n",
            "Epoch 410/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2969 - mae: 3476.2969\n",
            "Epoch 411/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.8940 - mae: 3476.8940\n",
            "Epoch 412/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.9087 - mae: 3477.9087\n",
            "Epoch 413/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1572 - mae: 3474.1572\n",
            "Epoch 414/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4414 - mae: 3475.4414\n",
            "Epoch 415/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2869 - mae: 3476.2869\n",
            "Epoch 416/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.3718 - mae: 3473.3718\n",
            "Epoch 417/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6055 - mae: 3473.6055\n",
            "Epoch 418/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.8220 - mae: 3476.8220\n",
            "Epoch 419/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3389 - mae: 3474.3389\n",
            "Epoch 420/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.8013 - mae: 3476.8013\n",
            "Epoch 421/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.1184 - mae: 3481.1184\n",
            "Epoch 422/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6895 - mae: 3473.6895\n",
            "Epoch 423/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.0713 - mae: 3478.0713\n",
            "Epoch 424/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.0261 - mae: 3476.0261\n",
            "Epoch 425/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.6055 - mae: 3472.6055\n",
            "Epoch 426/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.1941 - mae: 3481.1941\n",
            "Epoch 427/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7363 - mae: 3475.7363\n",
            "Epoch 428/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6213 - mae: 3474.6213\n",
            "Epoch 429/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.4185 - mae: 3475.4185\n",
            "Epoch 430/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.6821 - mae: 3474.6821\n",
            "Epoch 431/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.5867 - mae: 3473.5867\n",
            "Epoch 432/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6743 - mae: 3474.6743\n",
            "Epoch 433/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6045 - mae: 3478.6045\n",
            "Epoch 434/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.1248 - mae: 3478.1248\n",
            "Epoch 435/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.0574 - mae: 3479.0574\n",
            "Epoch 436/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.5134 - mae: 3475.5134\n",
            "Epoch 437/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7527 - mae: 3475.7527\n",
            "Epoch 438/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.0757 - mae: 3478.0757\n",
            "Epoch 439/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.2590 - mae: 3473.2590\n",
            "Epoch 440/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2544 - mae: 3477.2544\n",
            "Epoch 441/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0024 - mae: 3474.0024\n",
            "Epoch 442/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.2239 - mae: 3473.2239\n",
            "Epoch 443/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1865 - mae: 3476.1865\n",
            "Epoch 444/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.1235 - mae: 3475.1235\n",
            "Epoch 445/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.8525 - mae: 3472.8525\n",
            "Epoch 446/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.7651 - mae: 3476.7651\n",
            "Epoch 447/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3994 - mae: 3474.3994\n",
            "Epoch 448/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.1316 - mae: 3476.1316\n",
            "Epoch 449/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.0918 - mae: 3477.0918\n",
            "Epoch 450/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.2686 - mae: 3475.2686\n",
            "Epoch 451/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4592 - mae: 3476.4592\n",
            "Epoch 452/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.8411 - mae: 3474.8411\n",
            "Epoch 453/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8508 - mae: 3475.8508\n",
            "Epoch 454/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7292 - mae: 3474.7292\n",
            "Epoch 455/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.1284 - mae: 3473.1284\n",
            "Epoch 456/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.9363 - mae: 3477.9363\n",
            "Epoch 457/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9673 - mae: 3475.9673\n",
            "Epoch 458/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8860 - mae: 3473.8860\n",
            "Epoch 459/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.8660 - mae: 3474.8660\n",
            "Epoch 460/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.2561 - mae: 3475.2561\n",
            "Epoch 461/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.0234 - mae: 3474.0234\n",
            "Epoch 462/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.6558 - mae: 3477.6558\n",
            "Epoch 463/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9500 - mae: 3472.9500\n",
            "Epoch 464/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9312 - mae: 3474.9312\n",
            "Epoch 465/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.6741 - mae: 3477.6741\n",
            "Epoch 466/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1609 - mae: 3474.1609\n",
            "Epoch 467/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3430 - mae: 3476.3430\n",
            "Epoch 468/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.1877 - mae: 3474.1877\n",
            "Epoch 469/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8484 - mae: 3473.8484\n",
            "Epoch 470/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8044 - mae: 3474.8044\n",
            "Epoch 471/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.2698 - mae: 3475.2698\n",
            "Epoch 472/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9041 - mae: 3474.9041\n",
            "Epoch 473/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3726 - mae: 3474.3726\n",
            "Epoch 474/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7698 - mae: 3474.7698\n",
            "Epoch 475/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2524 - mae: 3477.2524\n",
            "Epoch 476/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6011 - mae: 3475.6011\n",
            "Epoch 477/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.9785 - mae: 3477.9785\n",
            "Epoch 478/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.4370 - mae: 3473.4370\n",
            "Epoch 479/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.0969 - mae: 3480.0969\n",
            "Epoch 480/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9133 - mae: 3474.9133\n",
            "Epoch 481/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6604 - mae: 3475.6604\n",
            "Epoch 482/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.1824 - mae: 3477.1824\n",
            "Epoch 483/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9819 - mae: 3475.9819\n",
            "Epoch 484/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.7837 - mae: 3474.7837\n",
            "Epoch 485/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.2092 - mae: 3474.2092\n",
            "Epoch 486/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.6091 - mae: 3481.6091\n",
            "Epoch 487/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.8547 - mae: 3479.8547\n",
            "Epoch 488/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.6450 - mae: 3472.6450\n",
            "Epoch 489/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.1299 - mae: 3473.1299\n",
            "Epoch 490/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2803 - mae: 3477.2803\n",
            "Epoch 491/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7798 - mae: 3475.7798\n",
            "Epoch 492/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.6143 - mae: 3473.6143\n",
            "Epoch 493/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5479 - mae: 3475.5479\n",
            "Epoch 494/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.3994 - mae: 3474.3994\n",
            "Epoch 495/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2148 - mae: 3477.2148\n",
            "Epoch 496/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8936 - mae: 3475.8936\n",
            "Epoch 497/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.0742 - mae: 3474.0742\n",
            "Epoch 498/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9873 - mae: 3475.9873\n",
            "Epoch 499/500\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.8589 - mae: 3476.8589\n",
            "Epoch 500/500\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.2285 - mae: 3476.2285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5e9bd7e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMkE-Nzc-VBt",
        "outputId": "bdfbb869-54f1-4495-8454-67fc9f1434c5"
      },
      "source": [
        "insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3160.7495 - mae: 3160.7495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4C59Osh-ftG",
        "outputId": "811c6e1b-21b1-487b-8a6b-61b781e3bd7f"
      },
      "source": [
        "\n",
        "# Compare modelling results from non-normalized data and normalized data\n",
        "insurance_model_3_mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3171.577392578125, 3171.577392578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_oxaGwI-t5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671fbce2-25d6-4f91-b22e-83e1eebc7329"
      },
      "source": [
        "#Lets use our model number 2\n",
        "\n",
        "#set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(50),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "\n",
        "#Fit the model\n",
        "insurance_model_3.fit(X_train_normal, y_train, epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 12122.4551 - mae: 12122.4551\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7648.9434 - mae: 7648.9434\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5989.5879 - mae: 5989.5879\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3933.2312 - mae: 3933.2312\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3631.3118 - mae: 3631.3118\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.4832 - mae: 3640.4832\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.0747 - mae: 3561.0747\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3656.8723 - mae: 3656.8723\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.5771 - mae: 3599.5771\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3555.4492 - mae: 3555.4492\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.1841 - mae: 3536.1841\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.0681 - mae: 3560.0681\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.9863 - mae: 3508.9863\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.8704 - mae: 3522.8704\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.1787 - mae: 3560.1787\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.6128 - mae: 3535.6128\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3557.2908 - mae: 3557.2908\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.7595 - mae: 3537.7595\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3567.5859 - mae: 3567.5859\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.3635 - mae: 3523.3635\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.4080 - mae: 3539.4080\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.9668 - mae: 3518.9668\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.1702 - mae: 3511.1702\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3568.8545 - mae: 3568.8545\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3601.1094 - mae: 3601.1094\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.2317 - mae: 3561.2317\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3606.1050 - mae: 3606.1050\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3603.5979 - mae: 3603.5979\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3543.4460 - mae: 3543.4460\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.0012 - mae: 3522.0012\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.8315 - mae: 3520.8315\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.3616 - mae: 3546.3616\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3571.2463 - mae: 3571.2463\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3617.1057 - mae: 3617.1057\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.3201 - mae: 3540.3201\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.9309 - mae: 3517.9309\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3510.8079 - mae: 3510.8079\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.4507 - mae: 3548.4507\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3582.4097 - mae: 3582.4097\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3575.6716 - mae: 3575.6716\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.3555 - mae: 3570.3555\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.1143 - mae: 3558.1143\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.6182 - mae: 3541.6182\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3562.6548 - mae: 3562.6548\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3503.5007 - mae: 3503.5007\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.1416 - mae: 3565.1416\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3555.5479 - mae: 3555.5479\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.5830 - mae: 3525.5830\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.4895 - mae: 3541.4895\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.6311 - mae: 3515.6311\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3510.4182 - mae: 3510.4182\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.4702 - mae: 3512.4702\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.0894 - mae: 3549.0894\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3550.0996 - mae: 3550.0996\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.6218 - mae: 3578.6218\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3553.8433 - mae: 3553.8433\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2749 - mae: 3538.2749\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.0642 - mae: 3520.0642\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.0237 - mae: 3496.0237\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.2166 - mae: 3559.2166\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.3701 - mae: 3534.3701\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.0842 - mae: 3545.0842\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.4082 - mae: 3558.4082\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.9680 - mae: 3511.9680\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.8625 - mae: 3519.8625\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.0876 - mae: 3534.0876\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.1912 - mae: 3537.1912\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.5815 - mae: 3531.5815\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.0420 - mae: 3521.0420\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.0823 - mae: 3528.0823\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.7073 - mae: 3511.7073\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.6826 - mae: 3531.6826\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.5039 - mae: 3590.5039\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3576.0317 - mae: 3576.0317\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3525.9663 - mae: 3525.9663\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.6084 - mae: 3536.6084\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.3997 - mae: 3519.3997\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.1726 - mae: 3512.1726\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3566.9668 - mae: 3566.9668\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.8789 - mae: 3611.8789\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.7810 - mae: 3624.7810\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3574.8713 - mae: 3574.8713\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.5925 - mae: 3536.5925\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.0557 - mae: 3590.0557\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.0789 - mae: 3525.0789\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.3726 - mae: 3538.3726\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.1309 - mae: 3549.1309\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.6836 - mae: 3532.6836\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.4041 - mae: 3508.4041\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.9458 - mae: 3527.9458\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.5444 - mae: 3535.5444\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3614.1458 - mae: 3614.1458\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3604.3779 - mae: 3604.3779\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.4375 - mae: 3531.4375\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.7170 - mae: 3525.7170\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.7444 - mae: 3521.7444\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3584.1057 - mae: 3584.1057\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.9507 - mae: 3527.9507\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.6633 - mae: 3548.6633\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.9241 - mae: 3508.9241\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.6787 - mae: 3513.6787\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3604.8267 - mae: 3604.8267\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2485 - mae: 3538.2485\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.0930 - mae: 3518.0930\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.6084 - mae: 3554.6084\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9041 - mae: 3524.9041\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.1042 - mae: 3531.1042\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3514.1023 - mae: 3514.1023\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.1133 - mae: 3548.1133\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.8315 - mae: 3516.8315\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.1851 - mae: 3545.1851\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.9192 - mae: 3549.9192\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3632.3586 - mae: 3632.3586\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.0098 - mae: 3541.0098\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.0144 - mae: 3528.0144\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3577.4253 - mae: 3577.4253\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.5908 - mae: 3509.5908\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3503.5942 - mae: 3503.5942\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.9075 - mae: 3491.9075\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.0835 - mae: 3491.0835\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.4731 - mae: 3525.4731\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.7302 - mae: 3540.7302\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3547.9287 - mae: 3547.9287\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.9272 - mae: 3522.9272\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9792 - mae: 3524.9792\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.6960 - mae: 3560.6960\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3514.8257 - mae: 3514.8257\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.2637 - mae: 3565.2637\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.9126 - mae: 3559.9126\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3576.8667 - mae: 3576.8667\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.7732 - mae: 3488.7732\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.7947 - mae: 3559.7947\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.8545 - mae: 3528.8545\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.5872 - mae: 3523.5872\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.6099 - mae: 3527.6099\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.1470 - mae: 3508.1470\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.0112 - mae: 3508.0112\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3539.8276 - mae: 3539.8276\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.1914 - mae: 3538.1914\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.2678 - mae: 3536.2678\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.0916 - mae: 3565.0916\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3570.1445 - mae: 3570.1445\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.4763 - mae: 3524.4763\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.8853 - mae: 3516.8853\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.1396 - mae: 3517.1396\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.9407 - mae: 3545.9404\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.5066 - mae: 3549.5066\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.1746 - mae: 3544.1746\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3500.9834 - mae: 3500.9834\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.9246 - mae: 3505.9246\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.8398 - mae: 3538.8398\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.8301 - mae: 3637.8301\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3517.3308 - mae: 3517.3308\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.5051 - mae: 3538.5051\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.2571 - mae: 3539.2571\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.1934 - mae: 3540.1934\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.4592 - mae: 3518.4592\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.6707 - mae: 3520.6707\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.5364 - mae: 3498.5364\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3603.5793 - mae: 3603.5793\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.4932 - mae: 3523.4932\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.9243 - mae: 3507.9243\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.8669 - mae: 3526.8669\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.5464 - mae: 3599.5464\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.0129 - mae: 3525.0129\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.4509 - mae: 3507.4509\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.7161 - mae: 3515.7161\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.0728 - mae: 3523.0728\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3526.8965 - mae: 3526.8965\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.0476 - mae: 3517.0476\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.8062 - mae: 3520.8062\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.3008 - mae: 3563.3008\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.1665 - mae: 3521.1665\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3499.3540 - mae: 3499.3540\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.3296 - mae: 3554.3296\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.8479 - mae: 3534.8479\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.6748 - mae: 3526.6748\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.1045 - mae: 3525.1045\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.1123 - mae: 3613.1123\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.2002 - mae: 3540.2002\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.7004 - mae: 3546.7004\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9160 - mae: 3524.9160\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.3467 - mae: 3515.3467\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.0664 - mae: 3549.0664\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.4170 - mae: 3535.4170\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3609.5723 - mae: 3609.5723\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.5720 - mae: 3536.5720\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.4702 - mae: 3520.4702\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.7400 - mae: 3545.7400\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.0251 - mae: 3537.0251\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.7617 - mae: 3552.7617\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.0896 - mae: 3559.0896\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.2307 - mae: 3558.2307\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.5505 - mae: 3509.5505\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3529.9670 - mae: 3529.9670\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.2437 - mae: 3528.2437\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3608.3560 - mae: 3608.3560\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.3396 - mae: 3522.3396\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.7922 - mae: 3536.7922\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.2996 - mae: 3502.2996\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3547.7129 - mae: 3547.7129\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.4304 - mae: 3545.4304\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.5032 - mae: 3521.5032\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2039 - mae: 3538.2039\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.5483 - mae: 3502.5483\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.5857 - mae: 3509.5857\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.4194 - mae: 3517.4194\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.5989 - mae: 3520.5989\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.8250 - mae: 3536.8250\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3564.5879 - mae: 3564.5879\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.8376 - mae: 3527.8376\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.4189 - mae: 3541.4189\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.9556 - mae: 3501.9556\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3493.1968 - mae: 3493.1968\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3651.1462 - mae: 3651.1462\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.4485 - mae: 3508.4485\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.5215 - mae: 3512.5215\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3550.8391 - mae: 3550.8391\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.4910 - mae: 3509.4910\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.8267 - mae: 3528.8267\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3586.4775 - mae: 3586.4775\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3666.2107 - mae: 3666.2107\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.0930 - mae: 3563.0930\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.7883 - mae: 3542.7883\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.1445 - mae: 3539.1445\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.6052 - mae: 3521.6052\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.8379 - mae: 3560.8379\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.1589 - mae: 3507.1589\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.5613 - mae: 3524.5613\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.5476 - mae: 3544.5476\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.8530 - mae: 3520.8530\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.4407 - mae: 3502.4407\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.1924 - mae: 3533.1924\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.6411 - mae: 3519.6411\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.1060 - mae: 3546.1060\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.4739 - mae: 3532.4739\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.1069 - mae: 3525.1069\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.0522 - mae: 3526.0522\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.9822 - mae: 3563.9822\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.5625 - mae: 3559.5625\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.9590 - mae: 3520.9590\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.1445 - mae: 3531.1445\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.2043 - mae: 3532.2043\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.1162 - mae: 3518.1162\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3739.4146 - mae: 3739.4146\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.7146 - mae: 3567.7146\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.1792 - mae: 3525.1792\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.1147 - mae: 3561.1147\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.4817 - mae: 3522.4817\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.9487 - mae: 3565.9487\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.4856 - mae: 3517.4856\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.0698 - mae: 3548.0698\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.1208 - mae: 3565.1208\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.7300 - mae: 3516.7300\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3506.2073 - mae: 3506.2073\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.9712 - mae: 3488.9712\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.8328 - mae: 3498.8328\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.6829 - mae: 3513.6829\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2395 - mae: 3538.2395\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.4080 - mae: 3520.4080\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3566.6580 - mae: 3566.6580\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.1494 - mae: 3523.1494\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3553.1116 - mae: 3553.1116\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3597.3447 - mae: 3597.3447\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.1523 - mae: 3549.1523\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.1526 - mae: 3505.1526\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3529.5493 - mae: 3529.5493\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.6929 - mae: 3507.6929\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.5298 - mae: 3517.5298\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3547.9209 - mae: 3547.9209\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.0278 - mae: 3502.0278\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3497.6738 - mae: 3497.6738\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.1008 - mae: 3559.1008\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3588.9856 - mae: 3588.9856\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3557.3921 - mae: 3557.3921\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.3093 - mae: 3524.3093\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.9304 - mae: 3517.9304\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.3254 - mae: 3511.3254\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3551.6873 - mae: 3551.6873\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.0020 - mae: 3542.0020\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.2864 - mae: 3533.2864\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3530.2446 - mae: 3530.2446\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3494.3071 - mae: 3494.3071\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3506.1082 - mae: 3506.1082\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.1418 - mae: 3558.1418\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3579.8787 - mae: 3579.8787\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.2422 - mae: 3559.2422\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.3193 - mae: 3505.3193\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.3838 - mae: 3511.3838\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.7700 - mae: 3549.7700\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.6924 - mae: 3513.6924\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3585.2861 - mae: 3585.2861\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.2312 - mae: 3519.2312\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.2354 - mae: 3542.2354\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.6436 - mae: 3534.6436\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.6309 - mae: 3516.6309\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.0735 - mae: 3539.0735\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3493.4846 - mae: 3493.4846\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.8833 - mae: 3531.8833\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.8884 - mae: 3563.8884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5e9955850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMiVcoqgSQ-d",
        "outputId": "f702377a-d25b-403c-e65e-48ad54185d4f"
      },
      "source": [
        "insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3172.6069 - mae: 3172.6069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og-gmgaPSaPi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}