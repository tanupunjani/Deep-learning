{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Detection NLP",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanupunjani/Mastering-tensorflow/blob/main/Emotion_Detection_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_UR84C68Fcy",
        "outputId": "5268b2b3-1248-4e07-b639-c0e98e90e5e1"
      },
      "source": [
        "!pip install aicrowd-cli"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aicrowd-cli\n",
            "  Downloading aicrowd_cli-0.1.9-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 600 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.56.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (4.62.0)\n",
            "Requirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n",
            "Collecting requests-toolbelt<1,>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.25.1\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 436 kB/s \n",
            "\u001b[?25hCollecting rich<11,>=10.0.0\n",
            "  Downloading rich-10.9.0-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 30.5 MB/s \n",
            "\u001b[?25hCollecting GitPython==3.1.18\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.18->aicrowd-cli) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2021.5.30)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n",
            "Installing collected packages: smmap, requests, gitdb, commonmark, colorama, rich, requests-toolbelt, GitPython, aicrowd-cli\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.18 aicrowd-cli-0.1.9 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 requests-2.26.0 requests-toolbelt-0.9.1 rich-10.9.0 smmap-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSsX9Rb97an9",
        "outputId": "ed945640-ce00-4d07-fa10-e0bffdf98c3f"
      },
      "source": [
        "API_KEY = '8db8021f6b44ed001637328f11a49992' # Please get your your API Key from [https://www.aicrowd.com/participants/me]\n",
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPoZQ0dBNZbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a771cc-d9f5-42b7-93e5-d1e1973e3171"
      },
      "source": [
        "# Downloading the Dataset\n",
        "!mkdir data\n",
        "!aicrowd dataset download --challenge emotion-detection -j 3 -o data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.csv: 100% 642k/642k [00:00<00:00, 982kB/s]\n",
            "train.csv:   0% 0.00/2.30M [00:00<?, ?B/s]\n",
            "val.csv:   0% 0.00/262k [00:00<?, ?B/s]\u001b[A\n",
            "val.csv: 100% 262k/262k [00:00<00:00, 515kB/s]\n",
            "train.csv: 100% 2.30M/2.30M [00:00<00:00, 2.43MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UdefMsDgnCB"
      },
      "source": [
        "#Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh2KbvK7gs2Q"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_csv(\"/content/data/train.csv\")\n",
        "valid_data = pd.read_csv(\"/content/data/val.csv\")\n",
        "test_data = pd.read_csv(\"/content/data/test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Khm0QnPRiSr1",
        "outputId": "7d0bcc10-8db1-4977-da4a-4cc03a413abd"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>takes no time to copy/paste a press release</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You're delusional</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jazz fan here. I completely feel. Lindsay Mann...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ah i was also confused but i think they mean f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you so much. ♥️ that means a lot.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0        takes no time to copy/paste a press release      0\n",
              "1                                  You're delusional      1\n",
              "2  Jazz fan here. I completely feel. Lindsay Mann...      0\n",
              "3  ah i was also confused but i think they mean f...      0\n",
              "4            Thank you so much. ♥️ that means a lot.      0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKKLcxrzilxH"
      },
      "source": [
        "#Problem definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQhe9VB9i3mK"
      },
      "source": [
        "##The problem aims to tell a computer to distinguish between positive and negative emotion. The model should be able to predict if its 1 (meaning positive) or 0 (meaning negative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGZ8s7MMj1fn"
      },
      "source": [
        "#Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "jAOd022tj4CN",
        "outputId": "01da294d-0fe4-4110-c20b-9e628a24c2d3"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was already over the edge with Cassie Zamora...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I think you're right. She has oodles of cash a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haha I love this. I used to give mine phone bo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Probably out of desperation as they going no a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sorry !! You’re real good at that!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8677</th>\n",
              "      <td>Yeah no...I would find it very demeaning</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8678</th>\n",
              "      <td>This is how mafia works</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8679</th>\n",
              "      <td>Ah thanks 👍🏻</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8680</th>\n",
              "      <td>I ask them straight why they don't respect my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8681</th>\n",
              "      <td>Annette Acosta also tends to out vote Annette ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8682 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     I was already over the edge with Cassie Zamora...      0\n",
              "1     I think you're right. She has oodles of cash a...      0\n",
              "2     Haha I love this. I used to give mine phone bo...      1\n",
              "3     Probably out of desperation as they going no a...      0\n",
              "4                   Sorry !! You’re real good at that!!      0\n",
              "...                                                 ...    ...\n",
              "8677           Yeah no...I would find it very demeaning      1\n",
              "8678                            This is how mafia works      0\n",
              "8679                                       Ah thanks 👍🏻      0\n",
              "8680  I ask them straight why they don't respect my ...      1\n",
              "8681  Annette Acosta also tends to out vote Annette ...      0\n",
              "\n",
              "[8682 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDdU6kkpkCvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "3ac804de-eaa3-44c0-b730-ce09f0e02d4a"
      },
      "source": [
        "#Shuffling training dataframes\n",
        "train_df_shuffled = train_data.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13976</th>\n",
              "      <td>Yaaaay!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>says the insecure idiot who just had to dig th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24501</th>\n",
              "      <td>Game still \"fun\" if you don't tryhard and play...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22477</th>\n",
              "      <td>Connie Drake learned to fight smarter, not har...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16658</th>\n",
              "      <td>And she jumped into sewage. Yeh, no.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "13976                                           Yaaaay!!      0\n",
              "3256   says the insecure idiot who just had to dig th...      0\n",
              "24501  Game still \"fun\" if you don't tryhard and play...      0\n",
              "22477  Connie Drake learned to fight smarter, not har...      0\n",
              "16658               And she jumped into sewage. Yeh, no.      1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "4bCnG3i6a5BR",
        "outputId": "b509694c-e411-4f8d-b737-2a1005607655"
      },
      "source": [
        "test_data.tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8677</th>\n",
              "      <td>Yeah no...I would find it very demeaning</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8678</th>\n",
              "      <td>This is how mafia works</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8679</th>\n",
              "      <td>Ah thanks 👍🏻</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8680</th>\n",
              "      <td>I ask them straight why they don't respect my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8681</th>\n",
              "      <td>Annette Acosta also tends to out vote Annette ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "8677           Yeah no...I would find it very demeaning      1\n",
              "8678                            This is how mafia works      0\n",
              "8679                                       Ah thanks 👍🏻      0\n",
              "8680  I ask them straight why they don't respect my ...      1\n",
              "8681  Annette Acosta also tends to out vote Annette ...      0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "R1R1DQvBbXcM",
        "outputId": "dc2d3d20-e985-461e-c95e-4f438fb3c5ca"
      },
      "source": [
        "valid_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>While I agree with my political views could be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im still starving</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>*Hey just noticed..* it's your **2nd Cakeday**...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>They just did. Check out the sticky post.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I hope so too, she deserves it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  While I agree with my political views could be...      0\n",
              "1                                  im still starving      1\n",
              "2  *Hey just noticed..* it's your **2nd Cakeday**...      0\n",
              "3          They just did. Check out the sticky post.      0\n",
              "4                    I hope so too, she deserves it.      0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "FBRWsF781n2o",
        "outputId": "a519eacf-dd4c-48df-b5a0-72d3abcb6d10"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I was already over the edge with Cassie Zamora...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I think you're right. She has oodles of cash a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Haha I love this. I used to give mine phone bo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Probably out of desperation as they going no a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sorry !! You’re real good at that!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8677</th>\n",
              "      <td>Yeah no...I would find it very demeaning</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8678</th>\n",
              "      <td>This is how mafia works</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8679</th>\n",
              "      <td>Ah thanks 👍🏻</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8680</th>\n",
              "      <td>I ask them straight why they don't respect my ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8681</th>\n",
              "      <td>Annette Acosta also tends to out vote Annette ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8682 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     I was already over the edge with Cassie Zamora...      0\n",
              "1     I think you're right. She has oodles of cash a...      0\n",
              "2     Haha I love this. I used to give mine phone bo...      1\n",
              "3     Probably out of desperation as they going no a...      0\n",
              "4                   Sorry !! You’re real good at that!!      0\n",
              "...                                                 ...    ...\n",
              "8677           Yeah no...I would find it very demeaning      1\n",
              "8678                            This is how mafia works      0\n",
              "8679                                       Ah thanks 👍🏻      0\n",
              "8680  I ask them straight why they don't respect my ...      1\n",
              "8681  Annette Acosta also tends to out vote Annette ...      0\n",
              "\n",
              "[8682 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO5kzBDz1o8Q",
        "outputId": "25f15c3a-cf4a-41c7-d1ad-7b5e73a6c05a"
      },
      "source": [
        "#counting the total samples\n",
        "len(train_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31255"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3livvQ77jq_",
        "outputId": "6212b90d-7a09-4554-9799-49e32707d032"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8682"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cedu1MPF7lSq",
        "outputId": "5754d5f3-637e-44e9-e3e5-6736f23822af"
      },
      "source": [
        "len(valid_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3473"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnmKar0v7nJg"
      },
      "source": [
        "#Visualize the samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilrlXeUA7tD0"
      },
      "source": [
        "##Lets visualize 5 random samples of train sentences at a time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NQzfmDp9x7c",
        "outputId": "3e4565d9-5983-493f-a9df-c62b7deebde7"
      },
      "source": [
        "import random\n",
        "random_index = random.randint(0, len(train_data)-5) #create indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"label\"]][random_index:random_index+5].itertuples():\n",
        "  _,text, label = row\n",
        "  print(f\"Label : {label}\", \"(Positive)\") if label > 0 else \"(negative)\"\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "Let people worship if they want to. It’s time for us to move forward and focus on bettering our own lives\n",
            "\n",
            "---\n",
            "\n",
            "Text:\n",
            "shouldve just given him the sum you usually pay and transfer the burden of awkwardness onto him\n",
            "\n",
            "---\n",
            "\n",
            "Text:\n",
            "Yeah, right. Jacob Jones can marry Jacob Jones for that matter, as it seems only his genius is keeping her on the throne.\n",
            "\n",
            "---\n",
            "\n",
            "Text:\n",
            "Lauren Smith seems to be trying to get the foul over making the 3 a lot this season.\n",
            "\n",
            "---\n",
            "\n",
            "Text:\n",
            "Most national subreddits are nowhere near *real* people, it's quite interesting to see the disparities.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfXqDvGuCRgc"
      },
      "source": [
        "#Convert abstract text lines into lists\n",
        "train_sentences = train_df_shuffled[\"text\"].to_numpy()\n",
        "val_sentences = valid_data[\"text\"].to_numpy()\n",
        "test_sentences = test_data[\"text\"].to_numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96fZ24YcFaiB",
        "outputId": "64d1969f-93ec-4354-ef64-30775bf7cee2"
      },
      "source": [
        "train_sentences[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Yaaaay!!',\n",
              "       'says the insecure idiot who just had to dig through my comment history to try to get back at me. lol creep',\n",
              "       'Game still \"fun\" if you don\\'t tryhard and play on QM but some people are trolling on other mode and that\\'s Can be hard for nerv.',\n",
              "       'Connie Drake learned to fight smarter, not harder. I love her development so much',\n",
              "       'And she jumped into sewage. Yeh, no.',\n",
              "       'It’s my favorite part of the whole week',\n",
              "       'One of he most useful things I’ve read on this site as a medical student. Thank you very much.',\n",
              "       \"As a contractor this is a huge nono. If it's not on paper it not on your wall either.\",\n",
              "       'It scares me that left to right is also possible for anyone',\n",
              "       'They really need to bring Amanda Weiss son back to do more flashback scenes of young Amanda Weiss. That would be SO GOOD'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PJVGPKlFcyh",
        "outputId": "09b09a04-4008-4979-9001-e1a79f8117fa"
      },
      "source": [
        "len(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31255"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aafIs_qhJQI5",
        "outputId": "b7ec366d-a821-41e1-ba6f-37737e820d8f"
      },
      "source": [
        "len(val_sentences)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3473"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saFBHmqvJcXB"
      },
      "source": [
        "train_labels = train_df_shuffled[\"label\"].to_numpy()\n",
        "val_labels = valid_data[\"label\"].to_numpy()\n",
        "test_labels = test_data[\"label\"].to_numpy()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXC-RkMZMmjK",
        "outputId": "6903ffc2-768e-4809-cf71-96af1b7220ec"
      },
      "source": [
        "train_labels[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VHfGZ0oMuAR"
      },
      "source": [
        "#Text vectorization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC2eKyKdPPLJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "#Use the default text vectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, #how many words in the vocabulary (all different kinds of text)\n",
        "                                    standardize = \"lower_and_strip_punctuation\",#how to process text\n",
        "                                    split = \"whitespace\", #how to split the tokens\n",
        "                                    ngrams = None, #create group of n-words\n",
        "                                    output_mode = \"int\", #how to map tokens to numbers\n",
        "                                    output_sequence_length=None)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew5HnVTzSmNd",
        "outputId": "4bc61e11-3355-4e6c-87c9-9e74597b0d00"
      },
      "source": [
        "#finding average numner of tokens in our reviews text\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5zay75oWDQF"
      },
      "source": [
        "max_vocab_length = 1000 #max number of words to have in our vocabulary\n",
        "max_lenght = 13 #max_length of our sequnces\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_sequence_length=13)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2wqlz9IW60W"
      },
      "source": [
        "# Map text_vectorizer to train sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvuURYeTXWyh"
      },
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B1LjTrhYcUN",
        "outputId": "65a9d4e5-45b5-47ca-f522-ac249a278fbf"
      },
      "source": [
        "#Creating a sample and tokenizing it\n",
        "sample_sentence = \"Tanvi is an expert AI Engineer\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 13), dtype=int64, numpy=array([[ 1,  8, 56,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z19mlTi5YrPa"
      },
      "source": [
        "#Cool ! Now we can choose any random sentence from our train sentences to check the text vectorization feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4kq5uBtZgbm",
        "outputId": "097e3903-67dd-4c65-8ac6-a34cfee50a56"
      },
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Orignal sentence:\\n{random_sentence}\\n\\nVectorized sentence:\")\n",
        "\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal sentence:\n",
            "She does have a great ass I’ve always thought so\n",
            "\n",
            "Vectorized sentence:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 13), dtype=int64, numpy=array([[ 59, 166,  23,   5, 106, 625, 329, 149, 148,  21,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbnVzpS4fJtJ"
      },
      "source": [
        "#Find the top 5 words and the bottom 5 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsMZ9ArjmLi"
      },
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbOFL91j2Ih"
      },
      "source": [
        "top_5_words = words_in_vocab[:5]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQmsmU98j6Oa",
        "outputId": "4aeddee5-9100-4f2d-c144-5198dc0b4005"
      },
      "source": [
        "top_5_words"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i', 'to']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G4MHSP-aj7dL",
        "outputId": "c659d6fd-5c26-4597-c82b-d89b5a495faa"
      },
      "source": [
        "bottom_5_words = words_in_vocab[-5]\n",
        "bottom_5_words"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bed'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu9AmkBLkLBh"
      },
      "source": [
        "#Creating an embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdgyJT_hmR7S",
        "outputId": "fe7b8894-e1ac-4583-b57f-4a9313f0554e"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length = max_lenght)\n",
        "embedding"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fa7969a76d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPVp1mgpL87"
      },
      "source": [
        "#Testing the embeddig layer on random sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0pAr4gQqXw4",
        "outputId": "f3dfcbba-9a6f-485d-b99c-ae1bd24a85cd"
      },
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "random_embedding = embedding(text_vectorizer([random_sentence]))\n",
        "print(f\"Random sentence: {random_sentence}\")\n",
        "random_embedding"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence: Ha ha manu plays shit football amirite guys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 13, 128), dtype=float32, numpy=\n",
              "array([[[-0.00249169,  0.00039764,  0.03355694, ..., -0.00961616,\n",
              "          0.04543768, -0.0253271 ],\n",
              "        [-0.00249169,  0.00039764,  0.03355694, ..., -0.00961616,\n",
              "          0.04543768, -0.0253271 ],\n",
              "        [-0.00309793,  0.00090615,  0.04355029, ...,  0.02279839,\n",
              "         -0.00905225, -0.04904077],\n",
              "        ...,\n",
              "        [-0.02963591,  0.03810528, -0.02284383, ..., -0.04210591,\n",
              "         -0.03589249, -0.01557285],\n",
              "        [-0.02963591,  0.03810528, -0.02284383, ..., -0.04210591,\n",
              "         -0.03589249, -0.01557285],\n",
              "        [-0.02963591,  0.03810528, -0.02284383, ..., -0.04210591,\n",
              "         -0.03589249, -0.01557285]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkosN2ktq3kZ"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQInoEr4q4sd",
        "outputId": "4e853860-673a-47d2-9fe9-d215efcdaa08"
      },
      "source": [
        "random_embedding[0][0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.00249169,  0.00039764,  0.03355694,  0.01102369, -0.04004641,\n",
              "        0.02127457,  0.03642469, -0.00845911,  0.04466   , -0.02467129,\n",
              "       -0.04276622, -0.04650741,  0.0302625 ,  0.00501063, -0.02073274,\n",
              "        0.04076665, -0.04440799, -0.01347589,  0.0450828 ,  0.01239821,\n",
              "        0.00723379,  0.01288632, -0.01122186,  0.04280797, -0.00955522,\n",
              "        0.04660921,  0.04811851, -0.03836304,  0.00790018,  0.00783   ,\n",
              "        0.01260884,  0.02863816, -0.00507995, -0.03304418,  0.046605  ,\n",
              "       -0.00229287,  0.02241473, -0.0487495 , -0.02474066,  0.01158885,\n",
              "       -0.02434257,  0.04666995, -0.04156928, -0.02865679,  0.01220808,\n",
              "        0.01406441,  0.01831507,  0.03389328,  0.01851174, -0.0023215 ,\n",
              "        0.04882671, -0.04516926,  0.01063726,  0.01105471,  0.04860776,\n",
              "       -0.01238495, -0.03673091, -0.01368611,  0.04675848, -0.02054814,\n",
              "       -0.00179414, -0.03340197,  0.00495118,  0.02819309,  0.03200645,\n",
              "        0.02308232,  0.01417304, -0.02466698, -0.01195178, -0.00899331,\n",
              "       -0.00200778,  0.04979466,  0.04543811, -0.02879371, -0.00690005,\n",
              "        0.04028715, -0.04581337,  0.01627253, -0.01375278, -0.03454678,\n",
              "       -0.03803415,  0.00669571,  0.04347515, -0.0030525 , -0.03674501,\n",
              "        0.03443923,  0.01322483,  0.02830391, -0.04734929, -0.02195809,\n",
              "       -0.03841127, -0.03236203,  0.0041787 ,  0.03510559,  0.00609093,\n",
              "        0.04028226, -0.04195589,  0.04854219, -0.02034296, -0.04739553,\n",
              "        0.01099867, -0.01356968,  0.01715845,  0.01336596, -0.00893231,\n",
              "       -0.03462447, -0.0419341 ,  0.0408343 , -0.03460487,  0.02671866,\n",
              "        0.03933934, -0.00422736, -0.04767359, -0.03816978, -0.00021685,\n",
              "       -0.04867803, -0.02795577,  0.01073738,  0.00130261, -0.02171639,\n",
              "        0.02199176, -0.01499898, -0.04201204,  0.03671104, -0.04112558,\n",
              "       -0.00961616,  0.04543768, -0.0253271 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoLtyxEOrmhM"
      },
      "source": [
        "#Getting the helper functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puPTv5Byt10Z",
        "outputId": "f1e294a5-7416-45d0-93af-b636566d028f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-05 23:03:37--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-05 23:03:38 (79.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCi-suNbuejO"
      },
      "source": [
        "from helper_functions import calculate_results, create_tensorboard_callback, accuracy_score ,precision_recall_fscore_support"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNODp4bUFlZZ"
      },
      "source": [
        "#Modelling a text dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qppDG_qkFpMI"
      },
      "source": [
        "### We are creating a benchmark for our experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsN_qL4YJtZc",
        "outputId": "df01d8aa-f40d-4b07-b94c-ddc57ca87fe5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Creating tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline ([\n",
        "                     (\"tfidf\", TfidfVectorizer()), #convert words to numbers using tfidf\n",
        "                     (\"clf\", MultinomialNB()) #model the text\n",
        "])\n",
        "\n",
        "#Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ7uMwt2M9_A"
      },
      "source": [
        "#Get the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q0r8Z1nNNla"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences,val_labels)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zST66uPWPSa_",
        "outputId": "5097e155-0665-4023-c915-3ff32b4931d4"
      },
      "source": [
        "print(f\"{baseline_score*100:.2f}%\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4dVO91fBIiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bccf37-451d-4bc5-a04b-326c76cdb5b5"
      },
      "source": [
        "#Make the predictions \n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoBxaJbrPaOk"
      },
      "source": [
        "#Using the transfer learning for our project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH1K1CyQ9MTh"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbf7VIA-Agc1",
        "outputId": "570dc9d6-c5a4-4552-81b1-71c65e7a3803"
      },
      "source": [
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0.06579109  0.01226765 -0.03711271 -0.00360206  0.05657576 -0.03709659\n",
            " -0.0402483  -0.04691624  0.04751117 -0.00626177  0.03339733 -0.03225748\n",
            " -0.02951182  0.05706123 -0.03125783 -0.01789836 -0.02796606  0.01856283\n",
            " -0.0374579  -0.0888266  -0.01428857  0.01822379 -0.00720385  0.01422425\n",
            "  0.01323723 -0.00044181 -0.00970582 -0.00105472 -0.04080107 -0.02575576\n",
            " -0.04882491  0.03869063 -0.01404163  0.05813107 -0.03477886  0.06209134\n",
            " -0.08300394 -0.06032129 -0.0708599   0.05222806  0.03551109 -0.05332186\n",
            "  0.00364079  0.04148    -0.05663498  0.07072239  0.01188438 -0.03316613\n",
            "  0.0146693  -0.02381066], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyiBiKBpBB3Y",
        "outputId": "d1536922-c2e4-4938-ccd3-ea11557235c3"
      },
      "source": [
        "embed_samples.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0PNbZS4DgSn"
      },
      "source": [
        "#Convert USE layer to keras layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], #shape of inputs coming\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_a26L8xEQcn"
      },
      "source": [
        "#Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "],name=\"model_1_USE\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZO-fpG3Kqy0"
      },
      "source": [
        "#compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oErTA11uLjYw",
        "outputId": "ee9c3c38-be3d-479d-9407-7fb76b908aec"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af7NaOj-OZ69"
      },
      "source": [
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lJcawA9N9wa"
      },
      "source": [
        "from helper_functions import create_tensorboard_callback"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788qkBVcLosY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb72800-9dae-4965-a8fb-bec78f6a8ea2"
      },
      "source": [
        "#Fit the data\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210905-230411\n",
            "Epoch 1/5\n",
            "977/977 [==============================] - 21s 19ms/step - loss: 0.4169 - accuracy: 0.8122 - val_loss: 0.3822 - val_accuracy: 0.8200\n",
            "Epoch 2/5\n",
            "977/977 [==============================] - 17s 17ms/step - loss: 0.3818 - accuracy: 0.8253 - val_loss: 0.3818 - val_accuracy: 0.8246\n",
            "Epoch 3/5\n",
            "977/977 [==============================] - 17s 17ms/step - loss: 0.3723 - accuracy: 0.8307 - val_loss: 0.3761 - val_accuracy: 0.8223\n",
            "Epoch 4/5\n",
            "977/977 [==============================] - 18s 19ms/step - loss: 0.3606 - accuracy: 0.8378 - val_loss: 0.3741 - val_accuracy: 0.8218\n",
            "Epoch 5/5\n",
            "977/977 [==============================] - 17s 17ms/step - loss: 0.3495 - accuracy: 0.8434 - val_loss: 0.3741 - val_accuracy: 0.8238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBJwNcbjOn9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6893cfd3-720b-4e2a-83c6-ddeff7835200"
      },
      "source": [
        "model_1_preds = model_1.predict(val_sentences)\n",
        "model_1_preds"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.383918  ],\n",
              "       [0.64990586],\n",
              "       [0.00597529],\n",
              "       ...,\n",
              "       [0.04681696],\n",
              "       [0.14647442],\n",
              "       [0.46213815]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDmqFZpxAplU",
        "outputId": "e46dbe4f-9467-4f15-e4f1-c90068485b66"
      },
      "source": [
        "model_1_preds_probs = tf.round(model_1_preds)\n",
        "model_1_preds_probs"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3473, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhkkjBExcA3A",
        "outputId": "05bbc0f8-9515-4e80-b39e-8c0930444171"
      },
      "source": [
        "#Calculating results\n",
        "model_1_results = calculate_results(val_labels, model_1_preds_probs)\n",
        "model_1_results"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.37834725021595,\n",
              " 'f1': 0.8082435564305078,\n",
              " 'precision': 0.8062120981517306,\n",
              " 'recall': 0.8237834725021596}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Q61M0OgYwX",
        "outputId": "3187a786-a58f-44c5-980a-4fe9dbc632eb"
      },
      "source": [
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.3550244745177,\n",
              " 'f1': 0.7052936108398501,\n",
              " 'precision': 0.8174126292071061,\n",
              " 'recall': 0.7935502447451771}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBr8qt8tehu2"
      },
      "source": [
        "#Comparing it to our baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hETz4DsBelE7"
      },
      "source": [
        "#Create a helper function to compare our baseline results to new model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0TLBT3ye68D"
      },
      "source": [
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}:{value:.2f}, New{key}: {new_model_results[key]:.2f}, Difference:{new_model_results[key]-value:.2f}\")\n",
        "\n",
        "    "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTU9U8Ozi-WJ",
        "outputId": "e1d1454c-dfe3-4df3-c4a8-498616b6f4bb"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
        "                                    new_model_results=model_1_results)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy:79.36, Newaccuracy: 82.38, Difference:3.02\n",
            "Baseline precision:0.82, Newprecision: 0.81, Difference:-0.01\n",
            "Baseline recall:0.79, Newrecall: 0.82, Difference:0.03\n",
            "Baseline f1:0.71, Newf1: 0.81, Difference:0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6r_5izej3ga"
      },
      "source": [
        "#Fine tuning our USE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0aIA-GkVWc"
      },
      "source": [
        "#Convert USE layer to keras layer\n",
        "sentence_encoder_layer_fine_tuning = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], #shape of inputs coming\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=True,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G76sKsuQkbn6"
      },
      "source": [
        "#Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer_fine_tuning,\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "],name=\"model_1_USE\")\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfWpkLVHrAML"
      },
      "source": [
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HojWulv8rWSM",
        "outputId": "095a12b4-9847-4116-add2-2a779444d7c6"
      },
      "source": [
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=3,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                      \"tf_hub_USE_fine_tuning\")])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_USE_fine_tuning/20210905-230642\n",
            "Epoch 1/3\n",
            "977/977 [==============================] - 235s 234ms/step - loss: 0.3887 - accuracy: 0.8268 - val_loss: 0.3544 - val_accuracy: 0.8425\n",
            "Epoch 2/3\n",
            "977/977 [==============================] - 228s 233ms/step - loss: 0.1537 - accuracy: 0.9400 - val_loss: 0.4232 - val_accuracy: 0.8362\n",
            "Epoch 3/3\n",
            "977/977 [==============================] - 227s 233ms/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 0.8155 - val_accuracy: 0.7964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS9LgcUHsF4g",
        "outputId": "8774c1b2-e0ad-493c-aeee-c708a1564954"
      },
      "source": [
        "model_2_preds = model_2.predict(val_sentences)\n",
        "model_2_preds"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6801223e-03],\n",
              "       [9.5350480e-01],\n",
              "       [1.3202550e-04],\n",
              "       ...,\n",
              "       [2.7959800e-04],\n",
              "       [6.1902869e-04],\n",
              "       [9.9834776e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr1w7eYr8MMK",
        "outputId": "c2eaba3e-d53b-4ad8-c77d-1dff53553814"
      },
      "source": [
        "model_2_preds_probs = tf.round(model_2_preds)\n",
        "model_2_preds_probs"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3473, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv07xIyl8UeU",
        "outputId": "df3a5229-e90f-40bb-aa58-eaff28c0f826"
      },
      "source": [
        "model_2_results = calculate_results(val_labels,\n",
        "                  model_2_preds_probs)\n",
        "model_2_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.64295997696516,\n",
              " 'f1': 0.804665753122935,\n",
              " 'precision': 0.8180489456515274,\n",
              " 'recall': 0.7964295997696516}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe1umaY0CcC-",
        "outputId": "0d1fabf3-ab22-4a4d-d49f-701ba7516945"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy:79.36, Newaccuracy: 79.64, Difference:0.29\n",
            "Baseline precision:0.82, Newprecision: 0.82, Difference:0.00\n",
            "Baseline recall:0.79, Newrecall: 0.80, Difference:0.00\n",
            "Baseline f1:0.71, Newf1: 0.80, Difference:0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHgbHjZqCqAQ",
        "outputId": "abfa1c4f-4e54-4e8b-8cc7-d58d472db56c"
      },
      "source": [
        "model_2_test_pred = model_2.predict(test_sentences)\n",
        "model_2_test_pred"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9814665e-01],\n",
              "       [5.2059339e-03],\n",
              "       [1.5099284e-04],\n",
              "       ...,\n",
              "       [3.8209918e-04],\n",
              "       [8.2416832e-01],\n",
              "       [3.0873576e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA_bHwCbC2Lx",
        "outputId": "a7d2bebc-518a-41f6-b696-acf8841a55a6"
      },
      "source": [
        "model_2_test_preds_probs = tf.round(model_2_test_pred)\n",
        "model_2_test_preds_probs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8682, 1), dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjwbJH0bDHuS",
        "outputId": "80d1611f-256a-433c-a6c9-de257e7b5d91"
      },
      "source": [
        "model_2_test_results = calculate_results(test_labels,model_2_test_preds_probs)\n",
        "model_2_test_results"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 49.78115641557245,\n",
              " 'f1': 0.4720959540344993,\n",
              " 'precision': 0.49932914976757015,\n",
              " 'recall': 0.4978115641557245}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLCrycMcEFr6",
        "outputId": "c3f3f9cd-0ea1-4181-a01e-4b90aa92d96f"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results, model_2_test_results)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy:79.36, Newaccuracy: 49.78, Difference:-29.57\n",
            "Baseline precision:0.82, Newprecision: 0.50, Difference:-0.32\n",
            "Baseline recall:0.79, Newrecall: 0.50, Difference:-0.30\n",
            "Baseline f1:0.71, Newf1: 0.47, Difference:-0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bupIYAVUEhrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bff3c712-60a2-4ed6-bb1d-2508604dfcf7"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-0.88.0-py2.py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.26.0)\n",
            "Collecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.7.0-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.5-py3-none-manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.3.1-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: importlib-metadata<5 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.6.4)\n",
            "Collecting ipython<8.0,>=7.23.1\n",
            "  Downloading ipython-7.27.0-py3-none-any.whl (787 kB)\n",
            "\u001b[K     |████████████████████████████████| 787 kB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.12.3)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.20-py3-none-any.whl (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.11.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=baddebeec39add04d47f178ce5dddd47f77c3f659f753502bd2662e8a29b1571\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built blinker\n",
            "Installing collected packages: prompt-toolkit, ipython, ipykernel, watchdog, validators, pydeck, blinker, base58, streamlit\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.3.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.27.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\u001b[0m\n",
            "Successfully installed base58-2.1.0 blinker-1.4 ipykernel-6.3.1 ipython-7.27.0 prompt-toolkit-3.0.20 pydeck-0.7.0 streamlit-0.88.0 validators-0.18.2 watchdog-2.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "ipykernel",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz3lvRTFTN1U",
        "outputId": "6b597933-8aac-4e38-e6aa-f195a5db9387"
      },
      "source": [
        "!streamlit hello"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  Welcome to Streamlit. Check out our demo in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.194.229.143:8501\u001b[0m\n",
            "\u001b[0m\n",
            "  Ready to create your own Python apps super quickly?\u001b[0m\n",
            "  Head over to \u001b[0m\u001b[1mhttps://docs.streamlit.io\u001b[0m\n",
            "\u001b[0m\n",
            "  May you create awesome apps!\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qeTgaGTTl3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}